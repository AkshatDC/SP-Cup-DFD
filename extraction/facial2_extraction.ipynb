{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5687,"status":"ok","timestamp":1736527952484,"user":{"displayName":"Deepfake Detection","userId":"16853363008574283880"},"user_tz":-330},"id":"LKxM6hkykYXM","outputId":"b9d5b3e6-27cc-4382-9850-3522ab10bd86"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n","Collecting mediapipe\n","  Downloading mediapipe-0.10.20-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.12.23)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.69.0)\n","Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n","Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n","Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.3.0)\n","Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\n","Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.10.0)\n","Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.10.0.84)\n","Collecting sounddevice>=0.4.4 (from mediapipe)\n","  Downloading sounddevice-0.5.1-py3-none-any.whl.metadata (1.4 kB)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.2.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n","Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n","Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n","Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (1.13.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.55.3)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.8)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (11.1.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.2.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n","Downloading mediapipe-0.10.20-cp310-cp310-manylinux_2_28_x86_64.whl (35.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sounddevice-0.5.1-py3-none-any.whl (32 kB)\n","Installing collected packages: sounddevice, mediapipe\n","Successfully installed mediapipe-0.10.20 sounddevice-0.5.1\n"]}],"source":["!pip install tensorflow mediapipe\n","\n","import os\n","import numpy as np\n","import pickle\n","from tqdm import tqdm\n","import tensorflow as tf\n","import mediapipe as mp\n","import cv2"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WCKOwleC2YDS","executionInfo":{"status":"ok","timestamp":1736530515500,"user_tz":-330,"elapsed":5001,"user":{"displayName":"Deepfake Detection","userId":"16853363008574283880"}},"outputId":"d8c33df7-3d5b-46ce-d0f1-66888030e8c3"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Error configuring GPU: Cannot set memory growth on device when virtual devices configured\n","Mixed precision enabled for speedup.\n","Processing real images...\n","Total images: 7000, Remaining images: 6855\n"]},{"output_type":"stream","name":"stderr","text":["Extracting Landmark Features: 100%|██████████| 33/33 [10:49<00:00, 19.68s/it]"]},{"output_type":"stream","name":"stdout","text":["Landmark feature extraction completed.\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["import os\n","import pickle\n","from tqdm import tqdm\n","import cv2\n","import tensorflow as tf\n","import mediapipe as mp\n","from concurrent.futures import ThreadPoolExecutor\n","\n","# GPU setup with minimal memory growth and precision\n","physical_devices = tf.config.list_physical_devices('GPU')\n","if physical_devices:\n","    for device in physical_devices:\n","        try:\n","            tf.config.experimental.set_memory_growth(device, True)\n","            tf.config.set_logical_device_configuration(\n","                device, [tf.config.LogicalDeviceConfiguration(memory_limit=10000)]\n","            )\n","            print(\"GPU configured with a memory limit of 10000 MB.\")\n","        except Exception as e:\n","            print(f\"Error configuring GPU: {e}\")\n","else:\n","    print(\"No GPU detected, running on CPU.\")\n","\n","try:\n","    tf.keras.mixed_precision.set_global_policy('mixed_float16')\n","    print(\"Mixed precision enabled for speedup.\")\n","except ValueError:\n","    print(\"Mixed precision not supported, running with default precision.\")\n","\n","# Function to save progress\n","def save_progress(filepath, data):\n","    with open(filepath, 'wb') as f:\n","        pickle.dump(data, f)\n","\n","# Function to load progress\n","def load_progress(filepath):\n","    if os.path.exists(filepath):\n","        try:\n","            with open(filepath, 'rb') as f:\n","                return pickle.load(f)\n","        except Exception as e:\n","            print(f\"Error loading checkpoint {filepath}: {e}\")\n","    return []\n","\n","# Function to extract landmarks from a single image\n","def extract_landmarks_from_image(image_path):\n","    mp_face_mesh = mp.solutions.face_mesh\n","    landmarks = [(0, 0, 0)] * 468  # Default empty landmarks in case of failure\n","\n","    try:\n","        image = cv2.imread(image_path)\n","        if image is None:\n","            print(f\"Failed to read image: {image_path}\")\n","            return image_path, landmarks\n","\n","        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        with mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, refine_landmarks=True) as face_mesh:\n","            results = face_mesh.process(image_rgb)\n","            if results.multi_face_landmarks:\n","                face_landmarks = results.multi_face_landmarks[0]\n","                landmarks = [(lm.x, lm.y, lm.z) for lm in face_landmarks.landmark]\n","    except Exception as e:\n","        print(f\"Error processing image {image_path}: {e}\")\n","\n","    return image_path, landmarks\n","\n","# Function to process images and save landmarks with checkpoints using multithreading\n","def extract_landmark_features_with_checkpoint(image_paths, checkpoint_path):\n","    saved_progress = load_progress(checkpoint_path)\n","    processed_images = {entry['image_path'] for entry in saved_progress}\n","    remaining_images = [img for img in image_paths if img not in processed_images]\n","\n","    print(f\"Total images: {len(image_paths)}, Remaining images: {len(remaining_images)}\")\n","\n","    def process_and_save(image_path):\n","        try:\n","            image_path, landmarks = extract_landmarks_from_image(image_path)\n","            saved_progress.append({'image_path': image_path, 'landmarks': landmarks})\n","        except Exception as e:\n","            print(f\"Error in thread processing image {image_path}: {e}\")\n","\n","    chunk_size = max(1, len(remaining_images) // (8 * 4))  # Optimize chunk size for batching\n","    with ThreadPoolExecutor(max_workers=16) as executor:  # Increase max_workers to utilize more threads\n","        for i in tqdm(range(0, len(remaining_images), chunk_size), desc=\"Extracting Landmark Features\"):\n","            chunk = remaining_images[i:i + chunk_size]\n","            executor.map(process_and_save, chunk)\n","            save_progress(checkpoint_path, saved_progress)  # Save after processing each chunk\n","\n","    return saved_progress\n","\n","if __name__ == \"__main__\":\n","    # Define paths and directories\n","    base_path = 'drive/MyDrive/SP_cup/features/fake/'\n","    os.makedirs(base_path, exist_ok=True)\n","\n","    real_images_path = 'drive/MyDrive/SP_cup/fake/fake-12/'\n","\n","    real_checkpoint = os.path.join(base_path, 'landmarks_fake11.pkl')\n","\n","    # Collect image paths efficiently\n","    def get_image_paths(folder_path):\n","        return [\n","            os.path.join(root, file)\n","            for root, _, files in os.walk(folder_path)\n","            for file in files if file.lower().endswith(('.jpg', '.jpeg', '.png'))\n","        ]\n","\n","    real_image_paths = get_image_paths(real_images_path)\n","\n","    # Extract landmark features\n","    print(\"Processing real images...\")\n","    landmark_features_real = extract_landmark_features_with_checkpoint(real_image_paths, real_checkpoint)\n","\n","    print(\"Landmark feature extraction completed.\")\n"]},{"cell_type":"code","source":["import os\n","import pickle\n","from tqdm import tqdm\n","import cv2\n","import tensorflow as tf\n","import mediapipe as mp\n","from concurrent.futures import ProcessPoolExecutor\n","\n","# GPU setup with minimal memory growth and precision\n","physical_devices = tf.config.list_physical_devices('GPU')\n","if physical_devices:\n","    for device in physical_devices:\n","        try:\n","            tf.config.experimental.set_memory_growth(device, True)\n","            tf.config.set_logical_device_configuration(\n","                device, [tf.config.LogicalDeviceConfiguration(memory_limit=10000)]\n","            )\n","            print(\"GPU configured with a memory limit of 10000 MB.\")\n","        except Exception as e:\n","            print(f\"Error configuring GPU: {e}\")\n","else:\n","    print(\"No GPU detected, running on CPU.\")\n","\n","try:\n","    tf.keras.mixed_precision.set_global_policy('mixed_float16')\n","    print(\"Mixed precision enabled for speedup.\")\n","except ValueError:\n","    print(\"Mixed precision not supported, running with default precision.\")\n","\n","# Function to save progress\n","def save_progress(filepath, data):\n","    with open(filepath, 'wb') as f:\n","        pickle.dump(data, f)\n","\n","# Function to load progress\n","def load_progress(filepath):\n","    if os.path.exists(filepath):\n","        try:\n","            with open(filepath, 'rb') as f:\n","                return pickle.load(f)\n","        except Exception as e:\n","            print(f\"Error loading checkpoint {filepath}: {e}\")\n","    return []\n","\n","# Function to extract landmarks from a single image\n","def extract_landmarks_from_image(image_path):\n","    \"\"\"Extract facial landmarks using MediaPipe from a given image.\"\"\"\n","    mp_face_mesh = mp.solutions.face_mesh\n","    landmarks = [(0, 0, 0)] * 468  # Default empty landmarks in case of failure\n","\n","    try:\n","        image = cv2.imread(image_path)\n","        if image is None:\n","            print(f\"Failed to read image: {image_path}\")\n","            return image_path, landmarks\n","\n","        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        with mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, refine_landmarks=True) as face_mesh:\n","            results = face_mesh.process(image_rgb)\n","            if results.multi_face_landmarks:\n","                face_landmarks = results.multi_face_landmarks[0]\n","                landmarks = [(lm.x, lm.y, lm.z) for lm in face_landmarks.landmark]\n","    except Exception as e:\n","        print(f\"Error processing image {image_path}: {e}\")\n","\n","    return image_path, landmarks\n","\n","# Wrapper function for multiprocessing\n","def process_image(image_path):\n","    return extract_landmarks_from_image(image_path)\n","\n","# Function to process images and save landmarks with checkpoints using multiprocessing\n","def extract_landmark_features_with_checkpoint(image_paths, checkpoint_path):\n","    saved_progress = load_progress(checkpoint_path)\n","    processed_images = {entry['image_path'] for entry in saved_progress}\n","    remaining_images = [img for img in image_paths if img not in processed_images]\n","\n","    print(f\"Total images: {len(image_paths)}, Remaining images: {len(remaining_images)}\")\n","\n","    chunk_size = max(1, len(remaining_images) // (8 * 4))  # Optimize chunk size for batching\n","    with ProcessPoolExecutor(max_workers=8) as executor:  # Use process-based parallelism\n","        for i in tqdm(range(0, len(remaining_images), chunk_size), desc=\"Extracting Landmark Features\"):\n","            chunk = remaining_images[i:i + chunk_size]\n","            results = list(executor.map(process_image, chunk))\n","\n","            # Append results and save progress\n","            saved_progress.extend({'image_path': img_path, 'landmarks': lm} for img_path, lm in results)\n","            save_progress(checkpoint_path, saved_progress)  # Save after processing each chunk\n","\n","    return saved_progress\n","\n","if __name__ == \"__main__\":\n","    # Define paths and directories\n","    base_path = 'drive/MyDrive/SP_cup/features/fake/'\n","    os.makedirs(base_path, exist_ok=True)\n","\n","    real_images_path = 'drive/MyDrive/SP_cup/fake/fake-17/'\n","\n","    real_checkpoint = os.path.join(base_path, 'landmarks_fake16.pkl')\n","\n","    # Collect image paths efficiently\n","    def get_image_paths(folder_path):\n","        return [\n","            os.path.join(root, file)\n","            for root, _, files in os.walk(folder_path)\n","            for file in files if file.lower().endswith(('.jpg', '.jpeg', '.png'))\n","        ]\n","\n","    real_image_paths = get_image_paths(real_images_path)\n","\n","    # Extract landmark features\n","    print(\"Processing real images...\")\n","    landmark_features_real = extract_landmark_features_with_checkpoint(real_image_paths, real_checkpoint)\n","\n","    print(\"Landmark feature extraction completed.\")\n"],"metadata":{"id":"rROkooIhCQiF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736533032899,"user_tz":-330,"elapsed":324517,"user":{"displayName":"Deepfake Detection","userId":"16853363008574283880"}},"outputId":"94315b15-2b06-4564-91f7-bb83189dd7f0"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Error configuring GPU: Cannot set memory growth on device when virtual devices configured\n","Mixed precision enabled for speedup.\n","Processing real images...\n","Total images: 4714, Remaining images: 4714\n"]},{"output_type":"stream","name":"stderr","text":["Extracting Landmark Features: 100%|██████████| 33/33 [05:22<00:00,  9.78s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Landmark feature extraction completed.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"3ugf94PhSWcd"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[],"mount_file_id":"1rPng1C4spz4UA0z2dHFaFPUKyaw3ToaS","authorship_tag":"ABX9TyOm1G46kLW49jBizyFgSZZN"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}