{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"16ZUitZpb1P54aKAkleNiiU2Wp4UOGiJA","authorship_tag":"ABX9TyMqBE8BtTXwenTUvyRuwL2S"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5_dbdWxj7anq","executionInfo":{"status":"ok","timestamp":1736591848654,"user_tz":-330,"elapsed":9620,"user":{"displayName":"SP cup DFD","userId":"05376908248595937360"}},"outputId":"5808f6ad-7288-40ac-e19b-f49c3cd5617b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n","Collecting mediapipe\n","  Downloading mediapipe-0.10.20-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.12.23)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.69.0)\n","Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n","Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n","Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.3.0)\n","Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\n","Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.10.0)\n","Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.10.0.84)\n","Collecting sounddevice>=0.4.4 (from mediapipe)\n","  Downloading sounddevice-0.5.1-py3-none-any.whl.metadata (1.4 kB)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.2.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n","Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n","Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n","Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (1.13.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.55.3)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.8)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (11.1.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.2.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n","Downloading mediapipe-0.10.20-cp310-cp310-manylinux_2_28_x86_64.whl (35.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sounddevice-0.5.1-py3-none-any.whl (32 kB)\n","Installing collected packages: sounddevice, mediapipe\n","Successfully installed mediapipe-0.10.20 sounddevice-0.5.1\n"]}],"source":["!pip install tensorflow mediapipe\n","\n","import os\n","import numpy as np\n","import pickle\n","from tqdm import tqdm\n","import tensorflow as tf\n","import mediapipe as mp\n","import cv2"]},{"cell_type":"code","source":["import os\n","import pickle\n","from tqdm import tqdm\n","import cv2\n","import tensorflow as tf\n","import mediapipe as mp\n","from concurrent.futures import ProcessPoolExecutor\n","\n","# GPU setup with minimal memory growth and precision\n","physical_devices = tf.config.list_physical_devices('GPU')\n","if physical_devices:\n","    for device in physical_devices:\n","        try:\n","            tf.config.experimental.set_memory_growth(device, True)\n","            tf.config.set_logical_device_configuration(\n","                device, [tf.config.LogicalDeviceConfiguration(memory_limit=10000)]\n","            )\n","            print(\"GPU configured with a memory limit of 10000 MB.\")\n","        except Exception as e:\n","            print(f\"Error configuring GPU: {e}\")\n","else:\n","    print(\"No GPU detected, running on CPU.\")\n","\n","try:\n","    tf.keras.mixed_precision.set_global_policy('mixed_float16')\n","    print(\"Mixed precision enabled for speedup.\")\n","except ValueError:\n","    print(\"Mixed precision not supported, running with default precision.\")\n","\n","# Function to save progress\n","def save_progress(filepath, data):\n","    with open(filepath, 'wb') as f:\n","        pickle.dump(data, f)\n","\n","# Function to load progress\n","def load_progress(filepath):\n","    if os.path.exists(filepath):\n","        try:\n","            with open(filepath, 'rb') as f:\n","                return pickle.load(f)\n","        except Exception as e:\n","            print(f\"Error loading checkpoint {filepath}: {e}\")\n","    return []\n","\n","# Function to extract landmarks from a single image\n","def extract_landmarks_from_image(image_path):\n","    \"\"\"Extract facial landmarks using MediaPipe from a given image.\"\"\"\n","    mp_face_mesh = mp.solutions.face_mesh\n","    landmarks = [(0, 0, 0)] * 468  # Default empty landmarks in case of failure\n","\n","    try:\n","        image = cv2.imread(image_path)\n","        if image is None:\n","            print(f\"Failed to read image: {image_path}\")\n","            return image_path, landmarks\n","\n","        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        with mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, refine_landmarks=True) as face_mesh:\n","            results = face_mesh.process(image_rgb)\n","            if results.multi_face_landmarks:\n","                face_landmarks = results.multi_face_landmarks[0]\n","                landmarks = [(lm.x, lm.y, lm.z) for lm in face_landmarks.landmark]\n","    except Exception as e:\n","        print(f\"Error processing image {image_path}: {e}\")\n","\n","    return image_path, landmarks\n","\n","# Wrapper function for multiprocessing\n","def process_image(image_path):\n","    return extract_landmarks_from_image(image_path)\n","\n","# Function to process images and save landmarks with checkpoints using multiprocessing\n","def extract_landmark_features_with_checkpoint(image_paths, checkpoint_path):\n","    saved_progress = load_progress(checkpoint_path)\n","    processed_images = {entry['image_path'] for entry in saved_progress}\n","    remaining_images = [img for img in image_paths if img not in processed_images]\n","\n","    print(f\"Total images: {len(image_paths)}, Remaining images: {len(remaining_images)}\")\n","\n","    chunk_size = max(1, len(remaining_images) // (8 * 4))  # Optimize chunk size for batching\n","    with ProcessPoolExecutor(max_workers=8) as executor:  # Use process-based parallelism\n","        for i in tqdm(range(0, len(remaining_images), chunk_size), desc=\"Extracting Landmark Features\"):\n","            chunk = remaining_images[i:i + chunk_size]\n","            results = list(executor.map(process_image, chunk))\n","\n","            # Append results and save progress\n","            saved_progress.extend({'image_path': img_path, 'landmarks': lm} for img_path, lm in results)\n","            save_progress(checkpoint_path, saved_progress)  # Save after processing each chunk\n","\n","    return saved_progress\n","\n","if __name__ == \"__main__\":\n","    # Define paths and directories\n","    base_path = 'drive/MyDrive/validation/real_valid/'\n","    os.makedirs(base_path, exist_ok=True)\n","\n","    real_images_path = 'drive/MyDrive/validation/real_valid/real/'\n","\n","    real_checkpoint = os.path.join(base_path, 'landmarks_real_valid.pkl')\n","\n","    # Collect image paths efficiently\n","    def get_image_paths(folder_path):\n","        return [\n","            os.path.join(root, file)\n","            for root, _, files in os.walk(folder_path)\n","            for file in files if file.lower().endswith(('.jpg', '.jpeg', '.png'))\n","        ]\n","\n","    real_image_paths = get_image_paths(real_images_path)\n","\n","    # Extract landmark features\n","    print(\"Processing real images...\")\n","    landmark_features_real = extract_landmark_features_with_checkpoint(real_image_paths, real_checkpoint)\n","\n","    print(\"Landmark feature extraction completed.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zTXTtOs97ef5","executionInfo":{"status":"ok","timestamp":1736592105282,"user_tz":-330,"elapsed":99702,"user":{"displayName":"SP cup DFD","userId":"05376908248595937360"}},"outputId":"c379fe3f-c169-4fbd-dd97-d6185eafe54e"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Error configuring GPU: Cannot set memory growth on device when virtual devices configured\n","Mixed precision enabled for speedup.\n","Processing real images...\n","Total images: 1548, Remaining images: 1548\n"]},{"output_type":"stream","name":"stderr","text":["Extracting Landmark Features: 100%|██████████| 33/33 [01:34<00:00,  2.88s/it]"]},{"output_type":"stream","name":"stdout","text":["Landmark feature extraction completed.\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.applications import EfficientNetB0\n","from tensorflow.keras.applications.efficientnet import preprocess_input\n","import pickle\n","from tqdm import tqdm\n","import cv2\n","from concurrent.futures import ThreadPoolExecutor\n","\n","# GPU setup\n","physical_devices = tf.config.list_physical_devices('GPU')\n","if physical_devices:\n","    for device in physical_devices:\n","        try:\n","            tf.config.experimental.set_memory_growth(device, True)\n","            tf.config.set_logical_device_configuration(\n","                device, [tf.config.LogicalDeviceConfiguration(memory_limit=10000)]  # Adjust as needed\n","            )\n","            print(f\"Configured GPU with a memory limit of 10000 MB.\")\n","        except Exception as e:\n","            print(f\"Error configuring GPU: {e}\")\n","else:\n","    print(\"No GPU detected, running on CPU.\")\n","\n","# Mixed precision setup\n","try:\n","    tf.keras.mixed_precision.set_global_policy('mixed_float16')\n","    print(\"Mixed precision enabled for speedup.\")\n","except ValueError:\n","    print(\"Mixed precision not supported, running with default precision.\")\n","\n","# Save and load progress functions\n","def save_progress(filepath, data):\n","    try:\n","        with open(filepath, 'wb') as f:\n","            pickle.dump(data, f)\n","        print(f\"Progress saved at: {filepath}\")\n","    except Exception as e:\n","        print(f\"Error saving progress: {e}\")\n","\n","def load_progress(filepath):\n","    if os.path.exists(filepath):\n","        try:\n","            with open(filepath, 'rb') as f:\n","                return pickle.load(f)\n","        except Exception as e:\n","            print(f\"Error loading progress: {e}\")\n","    return []\n","\n","# Image preprocessing\n","def preprocess_image(image_path):\n","    try:\n","        image = cv2.imread(image_path)\n","        if image is None:\n","            print(f\"Failed to read image: {image_path}\")\n","            return np.zeros((224, 224, 3), dtype=np.float32)\n","\n","        image = cv2.resize(image, (224, 224))\n","        image = preprocess_input(image.astype(np.float32))\n","        return image\n","    except Exception as e:\n","        print(f\"Error processing image {image_path}: {e}\")\n","        return np.zeros((224, 224, 3), dtype=np.float32)\n","\n","# Multithreaded preprocessing\n","def preprocess_images_multithreaded(image_files, num_threads=4):\n","    processed_images = []\n","    with ThreadPoolExecutor(max_workers=num_threads) as executor:\n","        results = list(tqdm(executor.map(preprocess_image, image_files), total=len(image_files), desc=\"Preprocessing images\"))\n","        processed_images.extend(results)\n","    return np.array(processed_images, dtype=np.float32)\n","\n","# Spatial feature extraction for individual images\n","def extract_spatial_features_for_images(image_dir, model, checkpoint_path, batch_size=32, save_interval=200, num_threads=4):\n","    features = load_progress(checkpoint_path) or []\n","    processed_images = {f['image_name'] for f in features if 'image_name' in f}\n","    all_images = [os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n","    remaining_images = [img for img in all_images if img not in processed_images]\n","\n","    print(f\"Total images: {len(all_images)}, Remaining images: {len(remaining_images)}\")\n","\n","    for i in tqdm(range(0, len(remaining_images), batch_size), desc=\"Extracting spatial features\"):\n","        batch_files = remaining_images[i:i+batch_size]\n","\n","        try:\n","            # Multithreaded preprocessing\n","            processed_batch = preprocess_images_multithreaded(batch_files, num_threads)\n","            dataset = tf.data.Dataset.from_tensor_slices(processed_batch).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n","\n","            features_batch = model.predict(dataset, verbose=1)\n","\n","            for img_path, feature in zip(batch_files, features_batch):\n","                features.append({'image_name': img_path, 'features': feature})\n","        except Exception as e:\n","            print(f\"Error extracting features for batch {i // batch_size + 1}: {e}\")\n","\n","        # Save progress periodically\n","        if len(features) % save_interval == 0:\n","            save_progress(checkpoint_path, features)\n","\n","    save_progress(checkpoint_path, features)\n","    return features\n","\n","if __name__ == \"__main__\":\n","    # Define paths\n","    base_path = 'drive/MyDrive/validation/fake_valid/'\n","    features_dir = 'drive/MyDrive/validation/fake_valid/'\n","    os.makedirs(features_dir, exist_ok=True)\n","\n","    real_images_dir = os.path.join(base_path, 'fake')\n","    real_checkpoint = os.path.join(features_dir, 'spatial_valid_fake.pkl')\n","\n","    # Load EfficientNet model\n","    efficientnet = EfficientNetB0(weights='imagenet', include_top=False, pooling='avg')\n","\n","    # Extract spatial features for real images\n","    print(\"Processing real images...\")\n","    spatial_features_real = extract_spatial_features_for_images(\n","        image_dir=real_images_dir,\n","        model=efficientnet,\n","        checkpoint_path=real_checkpoint,\n","        batch_size=32,\n","        save_interval=200,\n","        num_threads=4\n","    )\n","\n","    print(\"Spatial feature extraction for images completed.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RzFvI3qU8L6M","executionInfo":{"status":"ok","timestamp":1736592591592,"user_tz":-330,"elapsed":54068,"user":{"displayName":"SP cup DFD","userId":"05376908248595937360"}},"outputId":"18edd180-1e9a-49ab-87b7-19a028968b5b"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Error configuring GPU: Cannot set memory growth on device when virtual devices configured\n","Mixed precision enabled for speedup.\n","Processing real images...\n","Total images: 1524, Remaining images: 1524\n"]},{"output_type":"stream","name":"stderr","text":["Extracting spatial features:   0%|          | 0/48 [00:00<?, ?it/s]\n","Preprocessing images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Preprocessing images:  41%|████      | 13/32 [00:00<00:00, 125.20it/s]\u001b[A\n","Preprocessing images: 100%|██████████| 32/32 [00:14<00:00,  2.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n"]},{"output_type":"stream","name":"stderr","text":["Extracting spatial features:   2%|▏         | 1/48 [00:18<14:33, 18.59s/it]\n","Preprocessing images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Preprocessing images: 100%|██████████| 32/32 [00:00<00:00, 278.69it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","Preprocessing images: 100%|██████████| 32/32 [00:00<00:00, 207.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n"]},{"output_type":"stream","name":"stderr","text":["Extracting spatial features:  10%|█         | 5/48 [00:19<01:20,  1.88s/it]\n","Preprocessing images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Preprocessing images: 100%|██████████| 32/32 [00:00<00:00, 204.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n"]},{"output_type":"stream","name":"stderr","text":["Extracting spatial features:  12%|█▎        | 6/48 [00:20<00:55,  1.33s/it]\n","Preprocessing images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Preprocessing images: 100%|██████████| 32/32 [00:00<00:00, 165.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n"]},{"output_type":"stream","name":"stderr","text":["Extracting spatial features:  15%|█▍        | 7/48 [00:20<00:40,  1.02it/s]\n","Preprocessing images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Preprocessing images: 100%|██████████| 32/32 [00:00<00:00, 194.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n"]},{"output_type":"stream","name":"stderr","text":["Extracting spatial features:  17%|█▋        | 8/48 [00:20<00:29,  1.34it/s]\n","Preprocessing images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Preprocessing images: 100%|██████████| 32/32 [00:00<00:00, 197.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n"]},{"output_type":"stream","name":"stderr","text":["Extracting spatial features:  19%|█▉        | 9/48 [00:20<00:22,  1.70it/s]\n","Preprocessing images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Preprocessing images: 100%|██████████| 32/32 [00:00<00:00, 186.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n"]},{"output_type":"stream","name":"stderr","text":["Extracting spatial features:  21%|██        | 10/48 [00:21<00:18,  2.05it/s]\n","Preprocessing images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Preprocessing images: 100%|██████████| 32/32 [00:00<00:00, 174.67it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n"]},{"output_type":"stream","name":"stderr","text":["Extracting spatial features:  23%|██▎       | 11/48 [00:21<00:15,  2.34it/s]\n","Preprocessing images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Preprocessing images: 100%|██████████| 32/32 [00:00<00:00, 206.23it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n"]},{"output_type":"stream","name":"stderr","text":["Extracting spatial features:  25%|██▌       | 12/48 [00:21<00:13,  2.71it/s]\n","Preprocessing images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Preprocessing images: 100%|██████████| 32/32 [00:00<00:00, 196.00it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n"]},{"output_type":"stream","name":"stderr","text":["Extracting spatial features:  27%|██▋       | 13/48 [00:21<00:11,  3.03it/s]\n","Preprocessing images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Preprocessing images: 100%|██████████| 32/32 [00:00<00:00, 184.77it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n"]},{"output_type":"stream","name":"stderr","text":["Extracting spatial features:  29%|██▉       | 14/48 [00:22<00:10,  3.22it/s]\n","Preprocessing images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Preprocessing images: 100%|██████████| 32/32 [00:00<00:00, 206.60it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n"]},{"output_type":"stream","name":"stderr","text":["Extracting spatial features:  31%|███▏      | 15/48 [00:22<00:09,  3.46it/s]\n","Preprocessing images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Preprocessing images: 100%|██████████| 32/32 [00:00<00:00, 178.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"]},{"output_type":"stream","name":"stderr","text":["Extracting spatial features:  33%|███▎      | 16/48 [00:22<00:08,  3.57it/s]\n","Preprocessing images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Preprocessing images: 100%|██████████| 32/32 [00:00<00:00, 186.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"]},{"output_type":"stream","name":"stderr","text":["Extracting spatial features:  35%|███▌      | 17/48 [00:22<00:08,  3.70it/s]\n","Preprocessing images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Preprocessing images: 100%|██████████| 32/32 [00:00<00:00, 197.20it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n"]},{"output_type":"stream","name":"stderr","text":["Extracting spatial features:  38%|███▊      | 18/48 [00:23<00:08,  3.66it/s]\n","Preprocessing images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Preprocessing images: 100%|██████████| 32/32 [00:00<00:00, 203.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n"]},{"output_type":"stream","name":"stderr","text":["Extracting spatial features:  40%|███▉      | 19/48 [00:23<00:07,  3.70it/s]\n","Preprocessing images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Preprocessing images: 100%|██████████| 32/32 [00:00<00:00, 171.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"]},{"output_type":"stream","name":"stderr","text":["Extracting spatial features:  42%|████▏     | 20/48 [00:23<00:07,  3.71it/s]\n","Preprocessing images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Preprocessing images: 100%|██████████| 32/32 [00:00<00:00, 156.77it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","Extracting spatial features:  44%|████▍     | 21/48 [00:24<00:07,  3.52it/s]\n","Preprocessing images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Preprocessing images:  41%|████      | 13/32 [00:00<00:00, 117.74it/s]\u001b[A\n","Preprocessing images: 100%|██████████| 32/32 [00:00<00:00, 136.24it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","Extracting spatial features:  46%|████▌     | 22/48 [00:24<00:08,  3.24it/s]\n","Preprocessing images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Preprocessing images:  34%|███▍      | 11/32 [00:00<00:00, 104.85it/s]\u001b[A\n","Preprocessing images: 100%|██████████| 32/32 [00:00<00:00, 131.95it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","Extracting spatial features:  48%|████▊     | 23/48 [00:24<00:08,  3.09it/s]\n","Preprocessing images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Preprocessing images:  47%|████▋     | 15/32 [00:00<00:00, 145.61it/s]\u001b[A\n","Preprocessing images: 100%|██████████| 32/32 [00:00<00:00, 129.75it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n"]},{"output_type":"stream","name":"stderr","text":["Extracting spatial features:  50%|█████     | 24/48 [00:25<00:08,  2.98it/s]\n","Preprocessing images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Preprocessing images:  50%|█████     | 16/32 [00:00<00:00, 149.11it/s]\u001b[A\n","Preprocessing images: 100%|██████████| 32/32 [00:00<00:00, 149.14it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","Extracting spatial features:  52%|█████▏    | 25/48 [00:25<00:07,  2.89it/s]"]},{"output_type":"stream","name":"stdout","text":["Progress saved at: drive/MyDrive/validation/fake_valid/spatial_valid_fake.pkl\n"]},{"output_type":"stream","name":"stderr","text":["\n","Preprocessing images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Preprocessing images:  44%|████▍     | 14/32 [00:00<00:00, 133.20it/s]\u001b[A\n","Preprocessing images: 100%|██████████| 32/32 [00:00<00:00, 142.78it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","Extracting spatial features:  54%|█████▍    | 26/48 [00:25<00:07,  2.91it/s]\n","Preprocessing images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Preprocessing images: 100%|██████████| 32/32 [00:00<00:00, 135.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n"]},{"output_type":"stream","name":"stderr","text":["Extracting spatial features:  56%|█████▋    | 27/48 [00:26<00:07,  2.84it/s]\n","Preprocessing images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Preprocessing images: 100%|██████████| 32/32 [00:00<00:00, 168.90it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n"]},{"output_type":"stream","name":"stderr","text":["Extracting spatial features:  58%|█████▊    | 28/48 [00:26<00:06,  2.99it/s]\n","Preprocessing images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Preprocessing images:  38%|███▊      | 12/32 [00:00<00:00, 118.23it/s]\u001b[A\n","Preprocessing images: 100%|██████████| 32/32 [00:00<00:00, 120.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n"]},{"output_type":"stream","name":"stderr","text":["Extracting spatial features:  60%|██████    | 29/48 [00:26<00:06,  2.87it/s]\n","Preprocessing images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Preprocessing images: 100%|██████████| 32/32 [00:00<00:00, 153.02it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\n","Extracting spatial features:  62%|██████▎   | 30/48 [00:27<00:06,  2.85it/s]\n","Preprocessing images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Preprocessing images:  41%|████      | 13/32 [00:00<00:00, 118.48it/s]\u001b[A\n","Preprocessing images: 100%|██████████| 32/32 [00:00<00:00, 122.80it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n"]},{"output_type":"stream","name":"stderr","text":["Extracting spatial features:  65%|██████▍   | 31/48 [00:27<00:05,  2.86it/s]\n","Preprocessing images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Preprocessing images:  38%|███▊      | 12/32 [00:00<00:00, 108.32it/s]\u001b[A\n","Preprocessing images: 100%|██████████| 32/32 [00:00<00:00, 120.58it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n"]},{"output_type":"stream","name":"stderr","text":["Extracting spatial features:  67%|██████▋   | 32/48 [00:28<00:05,  2.76it/s]\n","Preprocessing images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Preprocessing images:  34%|███▍      | 11/32 [00:00<00:00, 102.53it/s]\u001b[A\n","Preprocessing images: 100%|██████████| 32/32 [00:00<00:00, 117.56it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n"]},{"output_type":"stream","name":"stderr","text":["Extracting spatial features:  69%|██████▉   | 33/48 [00:28<00:05,  2.75it/s]\n","Preprocessing images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Preprocessing images: 100%|██████████| 32/32 [00:00<00:00, 187.71it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n"]},{"output_type":"stream","name":"stderr","text":["Extracting spatial features:  71%|███████   | 34/48 [00:28<00:04,  2.92it/s]\n","Preprocessing images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Preprocessing images: 100%|██████████| 32/32 [00:00<00:00, 193.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n"]},{"output_type":"stream","name":"stderr","text":["Extracting spatial features:  73%|███████▎  | 35/48 [00:28<00:04,  3.20it/s]\n","Preprocessing images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Preprocessing images: 100%|██████████| 32/32 [00:00<00:00, 188.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n"]},{"output_type":"stream","name":"stderr","text":["Extracting spatial features:  75%|███████▌  | 36/48 [00:29<00:03,  3.37it/s]\n","Preprocessing images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Preprocessing images: 100%|██████████| 32/32 [00:00<00:00, 187.99it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n"]},{"output_type":"stream","name":"stderr","text":["Extracting spatial features:  77%|███████▋  | 37/48 [00:29<00:03,  3.43it/s]\n","Preprocessing images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Preprocessing images: 100%|██████████| 32/32 [00:00<00:00, 195.71it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n"]},{"output_type":"stream","name":"stderr","text":["Extracting spatial features:  79%|███████▉  | 38/48 [00:29<00:02,  3.61it/s]\n","Preprocessing images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Preprocessing images: 100%|██████████| 32/32 [00:00<00:00, 201.71it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n"]},{"output_type":"stream","name":"stderr","text":["Extracting spatial features:  81%|████████▏ | 39/48 [00:30<00:02,  3.65it/s]\n","Preprocessing images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Preprocessing images: 100%|██████████| 32/32 [00:00<00:00, 178.71it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n"]},{"output_type":"stream","name":"stderr","text":["Extracting spatial features:  83%|████████▎ | 40/48 [00:30<00:02,  3.68it/s]\n","Preprocessing images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Preprocessing images: 100%|██████████| 32/32 [00:00<00:00, 192.72it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n"]},{"output_type":"stream","name":"stderr","text":["Extracting spatial features:  85%|████████▌ | 41/48 [00:30<00:01,  3.80it/s]\n","Preprocessing images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Preprocessing images: 100%|██████████| 32/32 [00:00<00:00, 180.90it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n"]},{"output_type":"stream","name":"stderr","text":["Extracting spatial features:  88%|████████▊ | 42/48 [00:30<00:01,  3.81it/s]\n","Preprocessing images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Preprocessing images: 100%|██████████| 32/32 [00:00<00:00, 196.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n"]},{"output_type":"stream","name":"stderr","text":["Extracting spatial features:  90%|████████▉ | 43/48 [00:31<00:01,  3.88it/s]\n","Preprocessing images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Preprocessing images: 100%|██████████| 32/32 [00:00<00:00, 170.83it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n"]},{"output_type":"stream","name":"stderr","text":["Extracting spatial features:  92%|█████████▏| 44/48 [00:31<00:01,  3.80it/s]\n","Preprocessing images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Preprocessing images: 100%|██████████| 32/32 [00:00<00:00, 197.98it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n"]},{"output_type":"stream","name":"stderr","text":["Extracting spatial features:  94%|█████████▍| 45/48 [00:31<00:00,  3.79it/s]\n","Preprocessing images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Preprocessing images: 100%|██████████| 32/32 [00:00<00:00, 213.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n"]},{"output_type":"stream","name":"stderr","text":["Extracting spatial features:  96%|█████████▌| 46/48 [00:31<00:00,  3.95it/s]\n","Preprocessing images:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Preprocessing images: 100%|██████████| 32/32 [00:00<00:00, 186.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n"]},{"output_type":"stream","name":"stderr","text":["Extracting spatial features:  98%|█████████▊| 47/48 [00:32<00:00,  3.94it/s]\n","Preprocessing images:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n","Preprocessing images: 100%|██████████| 20/20 [00:00<00:00, 177.54it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step\n"]},{"output_type":"stream","name":"stderr","text":["Extracting spatial features: 100%|██████████| 48/48 [00:41<00:00,  1.15it/s]"]},{"output_type":"stream","name":"stdout","text":["Progress saved at: drive/MyDrive/validation/fake_valid/spatial_valid_fake.pkl\n","Spatial feature extraction for images completed.\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]}]}