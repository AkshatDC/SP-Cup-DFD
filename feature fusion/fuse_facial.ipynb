{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","mount_file_id":"1ggDR3psFD4OO6E-59haZuT9HE7dVyTpu","authorship_tag":"ABX9TyMiVU+0OCLqdwoYxbcKE23w"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u_KOAO3Bi-Ln","executionInfo":{"status":"ok","timestamp":1736362052061,"user_tz":-330,"elapsed":28348,"user":{"displayName":"Deepfake Detection","userId":"16853363008574283880"}},"outputId":"d72b426c-9dfe-404d-c927-d23da3b3f5bc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import os\n","import pickle\n","from concurrent.futures import ThreadPoolExecutor\n","import itertools\n","\n","# File paths and settings\n","file_path = 'drive/MyDrive/SP_cup/features/fake/'\n","output_file = os.path.join(file_path, 'merged_facial_fake.pkl')\n","pkl_files = [f'landmarks_fake{i}.pkl' for i in range(1, 17)]\n","\n","# Validate pickle files\n","def is_valid_pickle(file_path):\n","    try:\n","        with open(file_path, 'rb') as f:\n","            pickle.load(f)\n","        return True\n","    except Exception as e:\n","        print(f\"Invalid pickle file: {file_path}, Error: {e}\")\n","        return False\n","\n","# Load a single pickle file in chunks\n","def load_pkl_chunked(file, chunk_size=1000):\n","    with open(file, 'rb') as f:\n","        data = pickle.load(f)\n","        for i in range(0, len(data), chunk_size):\n","            yield data[i:i + chunk_size]\n","\n","# Save data incrementally to avoid memory overflow\n","def safe_save(data, output_file, mode='ab'):\n","    with open(output_file, mode) as f:\n","        pickle.dump(data, f)\n","\n","# Incremental merging\n","def incremental_merge(pkl_files, file_path, output_file, chunk_size=1000):\n","    processed_files = set()\n","\n","    # Check if the output file exists and is valid\n","    if os.path.exists(output_file):\n","        try:\n","            with open(output_file, 'rb') as f:\n","                while True:\n","                    data = pickle.load(f)\n","                    processed_files.update({entry['source_file'] for entry in data})\n","        except EOFError:\n","            print(\"Resuming from existing progress.\")\n","\n","    remaining_files = [file for file in pkl_files if file not in processed_files]\n","\n","    with ThreadPoolExecutor(max_workers=4) as executor:\n","        for file in remaining_files:\n","            full_path = os.path.join(file_path, file)\n","            print(f\"Processing: {file}\")\n","            for chunk in executor.map(load_pkl_chunked, [full_path], [chunk_size]):\n","                for data in chunk:\n","                    for entry in data:\n","                        entry['source_file'] = file\n","                    safe_save(data, output_file)\n","\n","            processed_files.add(file)\n","\n","    print(\"Merging complete.\")\n","    return output_file\n","\n","if __name__ == '__main__':\n","    # Validate pickle files\n","    valid_files = [file for file in pkl_files if is_valid_pickle(os.path.join(file_path, file))]\n","\n","    # Merge data\n","    final_output = incremental_merge(valid_files, file_path, output_file)\n","    print(f\"Data successfully merged into: {final_output}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4_eMs5jXkVAN","outputId":"400cf1bf-c02e-47e6-afa6-862fbd089a22","executionInfo":{"status":"ok","timestamp":1736534869994,"user_tz":-330,"elapsed":67123,"user":{"displayName":"Deepfake Detection","userId":"16853363008574283880"}}},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing: landmarks_fake1.pkl\n","Processing: landmarks_fake2.pkl\n","Processing: landmarks_fake3.pkl\n","Processing: landmarks_fake4.pkl\n","Processing: landmarks_fake5.pkl\n","Processing: landmarks_fake6.pkl\n","Processing: landmarks_fake7.pkl\n","Processing: landmarks_fake8.pkl\n","Processing: landmarks_fake9.pkl\n","Processing: landmarks_fake10.pkl\n","Processing: landmarks_fake11.pkl\n","Processing: landmarks_fake12.pkl\n","Processing: landmarks_fake13.pkl\n","Processing: landmarks_fake14.pkl\n","Processing: landmarks_fake15.pkl\n","Processing: landmarks_fake16.pkl\n","Merging complete.\n","Data successfully merged into: drive/MyDrive/SP_cup/features/fake/merged_facial_fake.pkl\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"T1eo2q5Lki4k"},"execution_count":null,"outputs":[]}]}