{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1dlUFMNms-HOOWjDFL1voYsFlUNM-WjZD","authorship_tag":"ABX9TyMCJpmSgWfEY/tiHE4/i0ID"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2deA9M8Um7u1","outputId":"5f0249df-83af-460b-c314-195c7892b203"},"outputs":[{"output_type":"stream","name":"stdout","text":["Configured GPU with memory growth.\n","Collecting image paths...\n"]},{"output_type":"stream","name":"stderr","text":["Scanning fake folders: 100%|██████████| 17/17 [00:01<00:00, 11.86it/s]\n","Scanning real folders: 100%|██████████| 17/17 [00:00<00:00, 33.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Shuffling dataset...\n","Splitting dataset into training and validation...\n","Building the model...\n","Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n","\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","Compiling the model...\n","Training the model...\n","Epoch 1/5\n","\u001b[1m   8/6341\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:22:46\u001b[0m 2s/step - accuracy: 0.5520 - loss: 0.7865"]}],"source":["import os\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications import EfficientNetB0  # Lighter architecture\n","from tensorflow.keras.layers import Dense, Flatten, Dropout\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from tqdm import tqdm\n","from sklearn.model_selection import train_test_split\n","\n","# GPU Configuration\n","physical_devices = tf.config.list_physical_devices('GPU')\n","if physical_devices:\n","    for device in physical_devices:\n","        tf.config.experimental.set_memory_growth(device, True)\n","    print(\"Configured GPU with memory growth.\")\n","else:\n","    print(\"No GPU detected, running on CPU.\")\n","\n","# Paths\n","FAKE_IMAGE_DIR = 'drive/MyDrive/fake'\n","REAL_IMAGE_DIR = 'drive/MyDrive/train-real'\n","\n","# Hyperparameters\n","IMAGE_SIZE = (96, 96)  # Reduced size\n","BATCH_SIZE = 16  # Smaller batch size for faster processing\n","EPOCHS = 5  # Temporarily reduced for faster feedback\n","LEARNING_RATE = 1e-4\n","MODEL_CHECKPOINT = 'best_model.keras'\n","\n","# Function to collect all image paths\n","def collect_image_paths(base_dir, category_name):\n","    image_paths = []\n","    for subfolder in tqdm(sorted(os.listdir(base_dir)), desc=f\"Scanning {category_name} folders\"):\n","        subfolder_path = os.path.join(base_dir, subfolder)\n","        if os.path.isdir(subfolder_path):  # Ensure it's a directory\n","            for img_file in os.listdir(subfolder_path):\n","                if img_file.endswith('.png'):  # Check for PNG images\n","                    image_paths.append(os.path.join(subfolder_path, img_file))\n","    return image_paths\n","\n","# Load all image paths\n","print(\"Collecting image paths...\")\n","fake_image_paths = collect_image_paths(FAKE_IMAGE_DIR, \"fake\")\n","real_image_paths = collect_image_paths(REAL_IMAGE_DIR, \"real\")\n","\n","# Labels: Fake = 0, Real = 1\n","fake_labels = [0] * len(fake_image_paths)\n","real_labels = [1] * len(real_image_paths)\n","\n","# Combine and shuffle data\n","print(\"Shuffling dataset...\")\n","all_image_paths = fake_image_paths + real_image_paths\n","all_labels = fake_labels + real_labels\n","indices = np.arange(len(all_image_paths))\n","np.random.shuffle(indices)\n","\n","all_image_paths = np.array(all_image_paths)[indices]\n","all_labels = np.array(all_labels)[indices]\n","\n","# Function to preprocess images using tf.data API\n","def preprocess_image(image_path):\n","    image = tf.io.read_file(image_path)\n","    image = tf.image.decode_png(image, channels=3)\n","    image = tf.image.resize(image, IMAGE_SIZE)\n","    image = tf.keras.applications.efficientnet.preprocess_input(image)  # Use EfficientNet's preprocessing\n","    return image\n","\n","# Create a tf.data Dataset\n","def create_dataset(image_paths, labels, batch_size):\n","    # Convert image paths to a Dataset\n","    image_paths = tf.data.Dataset.from_tensor_slices(image_paths)\n","    labels = tf.data.Dataset.from_tensor_slices(labels)\n","\n","    # Map preprocess function\n","    image_dataset = image_paths.map(lambda x: preprocess_image(x), num_parallel_calls=tf.data.AUTOTUNE)\n","\n","    # Combine image dataset and label dataset\n","    dataset = tf.data.Dataset.zip((image_dataset, labels))\n","\n","    # Shuffle, batch, and prefetch the dataset\n","    dataset = dataset.shuffle(buffer_size=1000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n","    return dataset\n","\n","# Split dataset into training and validation sets\n","print(\"Splitting dataset into training and validation...\")\n","X_train, X_val, y_train, y_val = train_test_split(\n","    all_image_paths, all_labels, test_size=0.2, random_state=42, stratify=all_labels\n",")\n","\n","# Create TensorFlow Dataset\n","train_dataset = create_dataset(X_train, y_train, BATCH_SIZE)\n","val_dataset = create_dataset(X_val, y_val, BATCH_SIZE)\n","\n","# Model Definition\n","print(\"Building the model...\")\n","base_model = EfficientNetB0(input_shape=(*IMAGE_SIZE, 3), include_top=False, weights='imagenet')\n","base_model.trainable = False  # Freeze base model\n","\n","x = Flatten()(base_model.output)\n","x = Dense(128, activation='relu')(x)\n","x = Dropout(0.5)(x)\n","output = Dense(1, activation='sigmoid')(x)\n","\n","model = Model(inputs=base_model.input, outputs=output)\n","\n","# Compile the model with mixed precision\n","print(\"Compiling the model...\")\n","tf.keras.mixed_precision.set_global_policy('mixed_float16')  # Enable mixed precision\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","\n","# Class weights to handle data imbalance\n","class_weights = {0: 0.5778843174070766, 1: 3.7098888238736105}\n","\n","# Callbacks\n","callbacks = [\n","    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1),\n","    ModelCheckpoint(MODEL_CHECKPOINT, monitor='val_loss', save_best_only=True, verbose=1)\n","]\n","\n","# Train the model\n","print(\"Training the model...\")\n","history = model.fit(\n","    train_dataset,\n","    validation_data=val_dataset,\n","    epochs=EPOCHS,\n","    class_weight=class_weights,  # Account for class imbalance\n","    callbacks=callbacks,\n","    verbose=1\n",")\n","\n","# Save the model\n","print(f\"Saving model to {MODEL_CHECKPOINT}...\")\n","model.save(MODEL_CHECKPOINT)\n","\n","print(\"Training complete.\")\n"]},{"cell_type":"code","source":["!pip install mediapipe opencv-python\n","!pip install xgboost"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YPsH0WVe4Vj_","executionInfo":{"status":"ok","timestamp":1737261968344,"user_tz":-330,"elapsed":19573,"user":{"displayName":"SP cup DFD","userId":"05376908248595937360"}},"outputId":"2de0b776-b1a6-4089-dc30-c9180870a8b8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting mediapipe\n","  Downloading mediapipe-0.10.20-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.10.0.84)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.4.0)\n","Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (24.3.0)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (24.12.23)\n","Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.4.33)\n","Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.4.33)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (3.10.0)\n","Requirement already satisfied: numpy<2 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.26.4)\n","Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.10.0.84)\n","Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.25.5)\n","Collecting sounddevice>=0.4.4 (from mediapipe)\n","  Downloading sounddevice-0.5.1-py3-none-any.whl.metadata (1.4 kB)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.2.0)\n","Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n","Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (0.4.1)\n","Requirement already satisfied: opt-einsum in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (3.4.0)\n","Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (1.13.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (4.55.3)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (24.2)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (11.1.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (3.2.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (2.8.2)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n","Downloading mediapipe-0.10.20-cp311-cp311-manylinux_2_28_x86_64.whl (35.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sounddevice-0.5.1-py3-none-any.whl (32 kB)\n","Installing collected packages: sounddevice, mediapipe\n","Successfully installed mediapipe-0.10.20 sounddevice-0.5.1\n","Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.26.4)\n","Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.13.1)\n"]}]},{"cell_type":"code","source":["# Step 1: Download the shape predictor file\n","!wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n","\n","# Step 2: Extract the downloaded bz2 file\n","!bunzip2 shape_predictor_68_face_landmarks.dat.bz2\n","\n","# Step 3: Set the correct path to the downloaded file\n","predictor_path = '/content/shape_predictor_68_face_landmarks.dat'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q623r8NL6_uv","executionInfo":{"status":"ok","timestamp":1737262759654,"user_tz":-330,"elapsed":10166,"user":{"displayName":"SP cup DFD","userId":"05376908248595937360"}},"outputId":"14f3c9b7-b982-468d-deff-c2f9781b3ef8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2025-01-19 04:59:07--  http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n","Resolving dlib.net (dlib.net)... 107.180.26.78\n","Connecting to dlib.net (dlib.net)|107.180.26.78|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 64040097 (61M)\n","Saving to: ‘shape_predictor_68_face_landmarks.dat.bz2’\n","\n","shape_predictor_68_ 100%[===================>]  61.07M  90.9MB/s    in 0.7s    \n","\n","2025-01-19 04:59:08 (90.9 MB/s) - ‘shape_predictor_68_face_landmarks.dat.bz2’ saved [64040097/64040097]\n","\n"]}]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import pandas as pd\n","import dlib\n","import cv2\n","from tqdm import tqdm\n","from concurrent.futures import ThreadPoolExecutor\n","from sklearn.model_selection import train_test_split\n","from xgboost import XGBClassifier\n","from sklearn.metrics import classification_report, accuracy_score\n","import joblib\n","import tensorflow as tf\n","\n","# GPU Configuration\n","physical_devices = tf.config.list_physical_devices('GPU')\n","if physical_devices:\n","    for device in physical_devices:\n","        tf.config.experimental.set_memory_growth(device, True)\n","    print(\"Configured GPU with memory growth.\")\n","else:\n","    print(\"No GPU detected, running on CPU.\")\n","\n","# Paths\n","FAKE_IMAGE_DIR = 'drive/MyDrive/fake'\n","REAL_IMAGE_DIR = 'drive/MyDrive/train-real'\n","OUTPUT_MODEL = 'landmark_model.joblib'\n","\n","# Hyperparameters\n","NUM_THREADS = 16  # Increased threads for faster processing\n","BATCH_SIZE = 64  # Batch size for image processing\n","RANDOM_STATE = 42\n","\n","# Dlib setup\n","predictor_path = '/content/shape_predictor_68_face_landmarks.dat'\n","detector = dlib.get_frontal_face_detector()\n","predictor = dlib.shape_predictor(predictor_path)\n","# Function to extract facial landmarks using Dlib\n","def extract_landmarks(image_path):\n","    try:\n","        image = cv2.imread(image_path)\n","        if image is None:\n","            return None\n","\n","        # Convert to grayscale for Dlib\n","        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","        faces = detector(gray, 1)\n","        if len(faces) == 0:\n","            return None\n","\n","        # Assume the first detected face is the target\n","        shape = predictor(gray, faces[0])\n","        landmarks = [(p.x, p.y) for p in shape.parts()]\n","        return np.array(landmarks).flatten()\n","\n","    except Exception as e:\n","        print(f\"Error processing {image_path}: {e}\")\n","        return None\n","\n","# Function to collect image paths\n","def collect_image_paths(base_dir):\n","    image_paths = []\n","    for root, _, files in os.walk(base_dir):\n","        for file in files:\n","            if file.endswith('.png'):\n","                image_paths.append(os.path.join(root, file))\n","    return image_paths\n","\n","# Parallelized landmark extraction with batch processing\n","def process_images_in_batches(image_paths):\n","    results = []\n","    with ThreadPoolExecutor(max_workers=NUM_THREADS) as executor:\n","        for result in tqdm(executor.map(extract_landmarks, image_paths), total=len(image_paths), desc=\"Extracting landmarks\"):\n","            results.append(result)\n","    return results\n","\n","# Collect and preprocess data\n","print(\"Collecting image paths...\")\n","fake_image_paths = collect_image_paths(FAKE_IMAGE_DIR)\n","real_image_paths = collect_image_paths(REAL_IMAGE_DIR)\n","\n","# Balance dataset by limiting fake samples to 2x real samples\n","print(\"Balancing dataset...\")\n","if len(fake_image_paths) > 2 * len(real_image_paths):\n","    fake_image_paths = np.random.choice(fake_image_paths, 2 * len(real_image_paths), replace=False)\n","\n","print(\"Extracting landmarks...\")\n","fake_landmarks = process_images_in_batches(fake_image_paths)\n","real_landmarks = process_images_in_batches(real_image_paths)\n","\n","# Filter out None values\n","fake_landmarks = [lm for lm in fake_landmarks if lm is not None]\n","real_landmarks = [lm for lm in real_landmarks if lm is not None]\n","\n","# Labels: Fake = 0, Real = 1\n","fake_labels = [0] * len(fake_landmarks)\n","real_labels = [1] * len(real_landmarks)\n","\n","# Combine and shuffle data\n","print(\"Combining and shuffling data...\")\n","all_landmarks = np.array(fake_landmarks + real_landmarks)\n","all_labels = np.array(fake_labels + real_labels)\n","\n","indices = np.arange(len(all_landmarks))\n","np.random.shuffle(indices)\n","all_landmarks = all_landmarks[indices]\n","all_labels = all_labels[indices]\n","\n","# Train-test split\n","X_train, X_val, y_train, y_val = train_test_split(all_landmarks, all_labels, test_size=0.2, random_state=RANDOM_STATE, stratify=all_labels)\n","\n","# Handle class imbalance using scale_pos_weight\n","scale_pos_weight = len(y_train[y_train == 0]) / len(y_train[y_train == 1])\n","\n","# Convert data to DMatrix for XGBoost (GPU acceleration)\n","import xgboost as xgb\n","train_dmatrix = xgb.DMatrix(X_train, label=y_train)\n","val_dmatrix = xgb.DMatrix(X_val, label=y_val)\n","\n","# XGBoost Parameters with GPU\n","params = {\n","    'objective': 'binary:logistic',\n","    'tree_method': 'gpu_hist',  # Use GPU acceleration\n","    'eval_metric': 'logloss',\n","    'scale_pos_weight': scale_pos_weight,\n","    'eta': 0.1,\n","    'max_depth': 6,\n","}\n","\n","# Train the model\n","print(\"Training XGBoost model on GPU...\")\n","evals = [(train_dmatrix, 'train'), (val_dmatrix, 'validation')]\n","model = xgb.train(params, train_dmatrix, num_boost_round=200, evals=evals, early_stopping_rounds=10, verbose_eval=10)\n","\n","# Save the model\n","print(f\"Saving model to {OUTPUT_MODEL}...\")\n","joblib.dump(model, OUTPUT_MODEL)\n","\n","# Evaluate model\n","print(\"Evaluating model...\")\n","y_pred = (model.predict(val_dmatrix) > 0.5).astype(int)\n","print(classification_report(y_val, y_pred))\n","print(f\"Validation Accuracy: {accuracy_score(y_val, y_pred):.4f}\")\n","\n","print(\"Processing complete.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yxSIN-Xn4RVW","executionInfo":{"status":"ok","timestamp":1737265188735,"user_tz":-330,"elapsed":2407636,"user":{"displayName":"SP cup DFD","userId":"05376908248595937360"}},"outputId":"8c5aad83-bd4c-474f-94ac-43e7bf7aefaf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Configured GPU with memory growth.\n","Collecting image paths...\n","Balancing dataset...\n","Extracting landmarks...\n"]},{"output_type":"stream","name":"stderr","text":["Extracting landmarks: 100%|██████████| 34180/34180 [27:24<00:00, 20.79it/s]\n","Extracting landmarks: 100%|██████████| 17090/17090 [12:24<00:00, 22.94it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Combining and shuffling data...\n","Training XGBoost model on GPU...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [05:39:42] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n","\n","    E.g. tree_method = \"hist\", device = \"cuda\"\n","\n","  warnings.warn(smsg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["[0]\ttrain-logloss:0.68931\tvalidation-logloss:0.69029\n","[10]\ttrain-logloss:0.66348\tvalidation-logloss:0.67391\n","[20]\ttrain-logloss:0.64413\tvalidation-logloss:0.66473\n","[30]\ttrain-logloss:0.62904\tvalidation-logloss:0.65725\n","[40]\ttrain-logloss:0.61605\tvalidation-logloss:0.65227\n","[50]\ttrain-logloss:0.60308\tvalidation-logloss:0.64746\n","[60]\ttrain-logloss:0.59278\tvalidation-logloss:0.64390\n","[70]\ttrain-logloss:0.58269\tvalidation-logloss:0.64017\n","[80]\ttrain-logloss:0.57208\tvalidation-logloss:0.63678\n","[90]\ttrain-logloss:0.56312\tvalidation-logloss:0.63354\n","[100]\ttrain-logloss:0.55468\tvalidation-logloss:0.63132\n","[110]\ttrain-logloss:0.54717\tvalidation-logloss:0.62967\n","[120]\ttrain-logloss:0.54035\tvalidation-logloss:0.62801\n","[130]\ttrain-logloss:0.53342\tvalidation-logloss:0.62575\n","[140]\ttrain-logloss:0.52602\tvalidation-logloss:0.62391\n","[150]\ttrain-logloss:0.51924\tvalidation-logloss:0.62215\n","[160]\ttrain-logloss:0.51165\tvalidation-logloss:0.61944\n","[170]\ttrain-logloss:0.50559\tvalidation-logloss:0.61800\n","[180]\ttrain-logloss:0.49808\tvalidation-logloss:0.61607\n","[190]\ttrain-logloss:0.49111\tvalidation-logloss:0.61420\n","[199]\ttrain-logloss:0.48637\tvalidation-logloss:0.61307\n","Saving model to landmark_model.joblib...\n","Evaluating model...\n","              precision    recall  f1-score   support\n","\n","           0       0.77      0.73      0.75      6818\n","           1       0.51      0.56      0.54      3410\n","\n","    accuracy                           0.68     10228\n","   macro avg       0.64      0.65      0.64     10228\n","weighted avg       0.68      0.68      0.68     10228\n","\n","Validation Accuracy: 0.6754\n","Processing complete.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [05:39:44] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n","\n","    E.g. tree_method = \"hist\", device = \"cuda\"\n","\n","  warnings.warn(smsg, UserWarning)\n"]}]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import pandas as pd\n","import dlib\n","import cv2\n","from tqdm import tqdm\n","from concurrent.futures import ThreadPoolExecutor\n","from sklearn.metrics import classification_report, accuracy_score\n","import joblib\n","import xgboost as xgb\n","\n","# GPU Configuration\n","import tensorflow as tf\n","physical_devices = tf.config.list_physical_devices('GPU')\n","if physical_devices:\n","    for device in physical_devices:\n","        tf.config.experimental.set_memory_growth(device, True)\n","    print(\"Configured GPU with memory growth.\")\n","else:\n","    print(\"No GPU detected, running on CPU.\")\n","\n","# Paths\n","FAKE_VALID_IMAGE_DIR = 'drive/MyDrive/validation/fake_valid/fake'\n","REAL_VALID_IMAGE_DIR = 'drive/MyDrive/validation/real_valid/real'\n","OUTPUT_MODEL = 'landmark_model.joblib'\n","\n","# Hyperparameters\n","NUM_THREADS = 16  # Increased threads for faster processing\n","\n","# Dlib setup\n","predictor_path = \"shape_predictor_68_face_landmarks.dat\"\n","detector = dlib.get_frontal_face_detector()\n","predictor = dlib.shape_predictor(predictor_path)\n","\n","# Function to extract facial landmarks using Dlib\n","def extract_landmarks(image_path):\n","    try:\n","        image = cv2.imread(image_path)\n","        if image is None:\n","            return None\n","\n","        # Convert to grayscale for Dlib\n","        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","        faces = detector(gray, 1)\n","        if len(faces) == 0:\n","            return None\n","\n","        # Assume the first detected face is the target\n","        shape = predictor(gray, faces[0])\n","        landmarks = [(p.x, p.y) for p in shape.parts()]\n","        return np.array(landmarks).flatten()\n","\n","    except Exception as e:\n","        print(f\"Error processing {image_path}: {e}\")\n","        return None\n","\n","# Function to collect image paths\n","def collect_image_paths(base_dir):\n","    image_paths = []\n","    for root, _, files in os.walk(base_dir):\n","        for file in files:\n","            if file.endswith('.png'):\n","                image_paths.append(os.path.join(root, file))\n","    return image_paths\n","\n","# Parallelized landmark extraction with batch processing\n","def process_images_in_batches(image_paths):\n","    results = []\n","    with ThreadPoolExecutor(max_workers=NUM_THREADS) as executor:\n","        for result in tqdm(executor.map(extract_landmarks, image_paths), total=len(image_paths), desc=\"Extracting landmarks\"):\n","            results.append(result)\n","    return results\n","\n","# Load model\n","print(\"Loading model...\")\n","model = joblib.load(OUTPUT_MODEL)\n","\n","# Collect validation image paths\n","print(\"Collecting validation image paths...\")\n","fake_valid_image_paths = collect_image_paths(FAKE_VALID_IMAGE_DIR)\n","real_valid_image_paths = collect_image_paths(REAL_VALID_IMAGE_DIR)\n","\n","# Extract landmarks for validation data\n","print(\"Extracting landmarks for validation data...\")\n","fake_valid_landmarks = process_images_in_batches(fake_valid_image_paths)\n","real_valid_landmarks = process_images_in_batches(real_valid_image_paths)\n","\n","# Filter out None values\n","fake_valid_landmarks = [lm for lm in fake_valid_landmarks if lm is not None]\n","real_valid_landmarks = [lm for lm in real_valid_landmarks if lm is not None]\n","\n","# Labels: Fake = 0, Real = 1\n","fake_valid_labels = [0] * len(fake_valid_landmarks)\n","real_valid_labels = [1] * len(real_valid_landmarks)\n","\n","# Combine validation data\n","print(\"Combining validation data...\")\n","valid_landmarks = np.array(fake_valid_landmarks + real_valid_landmarks)\n","valid_labels = np.array(fake_valid_labels + real_valid_labels)\n","\n","# Convert landmarks to DMatrix\n","print(\"Converting landmarks to DMatrix...\")\n","valid_dmatrix = xgb.DMatrix(valid_landmarks)\n","\n","# Predict using the model\n","print(\"Predicting on validation data...\")\n","y_pred = (model.predict(valid_dmatrix) > 0.5).astype(int)\n","\n","# Evaluate model\n","print(\"Evaluating model...\")\n","print(classification_report(valid_labels, y_pred))\n","print(f\"Validation Accuracy: {accuracy_score(valid_labels, y_pred):.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vYbXVynz7DIl","executionInfo":{"status":"ok","timestamp":1737265868823,"user_tz":-330,"elapsed":121598,"user":{"displayName":"SP cup DFD","userId":"05376908248595937360"}},"outputId":"68eac441-15ac-46db-bf65-2bce4f00b54d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Configured GPU with memory growth.\n","Loading model...\n","Collecting validation image paths...\n","Extracting landmarks for validation data...\n"]},{"output_type":"stream","name":"stderr","text":["Extracting landmarks: 100%|██████████| 1524/1524 [01:08<00:00, 22.14it/s]\n","Extracting landmarks: 100%|██████████| 1548/1548 [00:51<00:00, 30.25it/s]"]},{"output_type":"stream","name":"stdout","text":["Combining validation data...\n","Converting landmarks to DMatrix...\n","Predicting on validation data...\n","Evaluating model...\n","              precision    recall  f1-score   support\n","\n","           0       0.52      0.53      0.52      1521\n","           1       0.53      0.53      0.53      1546\n","\n","    accuracy                           0.53      3067\n","   macro avg       0.53      0.53      0.53      3067\n","weighted avg       0.53      0.53      0.53      3067\n","\n","Validation Accuracy: 0.5259\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [05:51:06] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n","\n","    E.g. tree_method = \"hist\", device = \"cuda\"\n","\n","  warnings.warn(smsg, UserWarning)\n"]}]},{"cell_type":"code","source":["output_dir = '/content/drive/MyDrive/model'\n","os.makedirs(output_dir, exist_ok=True)\n","\n","# Step 3: Define the output model path\n","OUTPUT_MODEL = os.path.join(output_dir, 'landmark_model.joblib')\n","\n","# Step 4: Save the model\n","joblib.dump(model, OUTPUT_MODEL)\n","\n","print(f\"Model saved to {OUTPUT_MODEL}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zLzYxxFLGCOe","executionInfo":{"status":"ok","timestamp":1737266402044,"user_tz":-330,"elapsed":8,"user":{"displayName":"SP cup DFD","userId":"05376908248595937360"}},"outputId":"0abcb820-0b14-4b02-f721-89ec554a3872"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model saved to /content/drive/MyDrive/model/landmark_model.joblib\n"]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import numpy as np\n","from multiprocessing import Pool, cpu_count\n","from concurrent.futures import ThreadPoolExecutor, as_completed\n","from tqdm import tqdm\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils.class_weight import compute_class_weight\n","from sklearn.metrics import classification_report, accuracy_score\n","from xgboost import XGBClassifier\n","import joblib\n","import pickle\n","\n","# Paths\n","FAKE_IMAGE_DIR = 'drive/MyDrive/fake'\n","REAL_IMAGE_DIR = 'drive/MyDrive/train-real'\n","OUTPUT_MODEL = 'landmark_model.joblib'\n","CHECKPOINT_PATH_FAKE = 'fake_checkpoint.pkl'\n","CHECKPOINT_PATH_REAL = 'real_checkpoint.pkl'\n","FEATURES_PATH = 'extracted_features.pkl'\n","\n","# Hyperparameters\n","NUM_THREADS = 8  # Number of threads per batch\n","NUM_PROCESSES = min(4, cpu_count())  # Number of parallel processes\n","BATCH_SIZE = 1000  # Buffered batch size for disk I/O\n","RANDOM_STATE = 52\n","\n","# Function to collect image paths\n","def collect_image_paths(base_dir):\n","    image_paths = []\n","    for root, _, files in os.walk(base_dir):\n","        for file in files:\n","            if file.endswith('.png'):\n","                image_paths.append(os.path.join(root, file))\n","    return image_paths\n","\n","# Image processing function\n","def process_image(image_path):\n","    try:\n","        image = cv2.imread(image_path)\n","        if image is None:\n","            raise ValueError(\"Image not loaded\")\n","        image = cv2.resize(image, (224, 224))  # Resize to 224x224\n","        image = image / 255.0  # Normalize the image\n","        return image.flatten()  # Flatten to 1D\n","    except Exception as e:\n","        print(f\"Error processing {image_path}: {e}\")\n","        return None\n","\n","# Multiprocessing wrapper\n","def process_images_batch(batch_paths):\n","    results = []\n","    with ThreadPoolExecutor(max_workers=NUM_THREADS) as executor:\n","        futures = {executor.submit(process_image, path): path for path in batch_paths}\n","        for future in as_completed(futures):\n","            result = future.result()\n","            if result is not None:\n","                results.append(result)\n","    return results\n","\n","# Extract features with multiprocessing\n","def extract_features_in_batches(image_paths, checkpoint_path, batch_size=1000):\n","    start_idx = 0\n","    features = []\n","\n","    # Load checkpoint if it exists\n","    if os.path.exists(checkpoint_path):\n","        with open(checkpoint_path, 'rb') as f:\n","            checkpoint_data = pickle.load(f)\n","            start_idx = checkpoint_data.get('start_idx', 0)\n","            features = checkpoint_data.get('features', [])\n","        print(f\"Resuming from batch {start_idx}, loaded {len(features)} features.\")\n","\n","    # Split paths into batches\n","    batches = [image_paths[i:i + batch_size] for i in range(start_idx, len(image_paths), batch_size)]\n","\n","    # Process batches with multiprocessing\n","    with Pool(processes=NUM_PROCESSES) as pool:\n","        for batch_idx, batch_features in enumerate(\n","            tqdm(pool.imap(process_images_batch, batches), total=len(batches), desc=\"Processing batches\")\n","        ):\n","            features.extend(batch_features)\n","\n","            # Save progress after each batch\n","            with open(checkpoint_path, 'wb') as f:\n","                pickle.dump({'start_idx': (batch_idx + 1) * batch_size, 'features': features}, f)\n","\n","    return features\n","\n","# Collect image paths\n","print(\"Collecting image paths...\")\n","fake_image_paths = collect_image_paths(FAKE_IMAGE_DIR)\n","real_image_paths = collect_image_paths(REAL_IMAGE_DIR)\n","print(f\"Number of fake images: {len(fake_image_paths)}\")\n","print(f\"Number of real images: {len(real_image_paths)}\")\n","\n","# Balance dataset\n","if len(fake_image_paths) > 2 * len(real_image_paths):\n","    fake_image_paths = np.random.choice(fake_image_paths, 2 * len(real_image_paths), replace=False)\n","print(f\"Reduced fake images to {len(fake_image_paths)}\")\n","\n","# Extract features for fake and real images\n","print(\"Extracting features for fake images...\")\n","fake_features = extract_features_in_batches(fake_image_paths, CHECKPOINT_PATH_FAKE, BATCH_SIZE)\n","\n","print(\"Extracting features for real images...\")\n","real_features = extract_features_in_batches(real_image_paths, CHECKPOINT_PATH_REAL, BATCH_SIZE)\n","\n","# Validate extracted features\n","assert len(fake_features) > 0, \"No fake features extracted!\"\n","assert len(real_features) > 0, \"No real features extracted!\"\n","\n","# Save the extracted features in separate files\n","with open('fake_features.pkl', 'wb') as f:\n","    pickle.dump(fake_features, f)\n","\n","with open('real_features.pkl', 'wb') as f:\n","    pickle.dump(real_features, f)\n","\n","print(f\"Extracted fake features saved to fake_features.pkl\")\n","print(f\"Extracted real features saved to real_features.pkl\")\n","\n","# Prepare dataset\n","all_features = np.array(fake_features + real_features)\n","all_labels = np.array([0] * len(fake_features) + [1] * len(real_features))\n","\n","# Shuffle and split the dataset\n","indices = np.arange(len(all_features))\n","np.random.shuffle(indices)\n","all_features = all_features[indices]\n","all_labels = all_labels[indices]\n","\n","X_train, X_val, y_train, y_val = train_test_split(\n","    all_features, all_labels, test_size=0.2, random_state=RANDOM_STATE, stratify=all_labels\n",")\n","\n","# Check if both classes are present in the training set\n","if len(np.unique(y_train)) < 2:\n","    raise ValueError(\"Training set has only one class. Ensure both fake and real images are properly loaded.\")\n","\n","# Compute class weights\n","class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n","class_weight_dict = {0: class_weights[0], 1: class_weights[1]}\n","print(f\"Class weights: {class_weight_dict}\")\n","\n","# Train the model\n","print(\"Training XGBoost model...\")\n","model = XGBClassifier(scale_pos_weight=class_weight_dict[0] / class_weight_dict[1], use_label_encoder=False, eval_metric=\"logloss\")\n","model.fit(X_train, y_train, sample_weight=np.array([class_weight_dict[label] for label in y_train]))\n","\n","# Save the model\n","joblib.dump(model, OUTPUT_MODEL)\n","print(f\"Model saved to {OUTPUT_MODEL}\")\n","\n","# Evaluate the model\n","print(\"Evaluating model...\")\n","y_pred = model.predict(X_val)\n","print(classification_report(y_val, y_pred))\n","print(f\"Validation Accuracy: {accuracy_score(y_val, y_pred):.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":454},"id":"NP1MgGbbKtcZ","outputId":"af6fb85f-bbdb-42fd-d2be-6a59b8e1bf80","executionInfo":{"status":"error","timestamp":1737278504393,"user_tz":-330,"elapsed":15628,"user":{"displayName":"SP cup DFD","userId":"05376908248595937360"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting image paths...\n","Number of fake images: 109714\n","Number of real images: 17090\n","Reduced fake images to 34180\n","Extracting features for fake images...\n"]},{"output_type":"error","ename":"UnpicklingError","evalue":"pickle data was truncated","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-5aef1675d851>\u001b[0m in \u001b[0;36m<cell line: 104>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;31m# Extract features for fake and real images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Extracting features for fake images...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m \u001b[0mfake_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_features_in_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_image_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCHECKPOINT_PATH_FAKE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Extracting features for real images...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-2-5aef1675d851>\u001b[0m in \u001b[0;36mextract_features_in_batches\u001b[0;34m(image_paths, checkpoint_path, batch_size)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mcheckpoint_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0mstart_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'start_idx'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnpicklingError\u001b[0m: pickle data was truncated"]}]},{"cell_type":"code","source":["import pickle\n","\n","FAKE_FEATURES_PATH = 'fake_checkpoint.pkl'\n","\n","try:\n","    with open(FAKE_FEATURES_PATH, 'rb') as f:\n","        data = pickle.load(f)\n","    print(f\"Data type in fake_features.pkl: {type(data)}\")\n","    print(data)  # Print the data to see what's inside\n","except FileNotFoundError:\n","    print(\"No fake features file found.\")\n","except EOFError:\n","    print(\"Fake features file is empty or corrupted.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oQu7S6alOz1y","executionInfo":{"status":"ok","timestamp":1737274657139,"user_tz":-330,"elapsed":438,"user":{"displayName":"SP cup DFD","userId":"05376908248595937360"}},"outputId":"123ea262-2063-4755-8382-8ec93e22eb6f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Data type in fake_features.pkl: <class 'int'>\n","8000\n"]}]},{"cell_type":"code","source":["import pickle\n","import joblib\n","import numpy as np\n","\n","# Define the paths\n","model_path = \"drive/MyDrive/model/landmark_model.joblib\"\n","fake_data_path = \"drive/MyDrive/validation/valid_fake_landmarks.pkl\"\n","real_data_path = \"drive/MyDrive/validation/valid_real_landmarks.pkl\"\n","output_file = \"submission.txt\"\n","\n","# Load the model\n","print(\"Loading model...\")\n","model = joblib.load(model_path)\n","\n","# Load the validation data\n","print(\"Loading validation data...\")\n","with open(fake_data_path, \"rb\") as f:\n","    fake_landmarks = pickle.load(f)\n","with open(real_data_path, \"rb\") as f:\n","    real_landmarks = pickle.load(f)\n","\n","# Preprocess data\n","print(\"Preparing data...\")\n","def preprocess_data(data, target_length=1280):\n","    processed_data = []\n","    for item in data:\n","        item = np.array(item).flatten()\n","        if len(item) < target_length:\n","            item = np.pad(item, (0, target_length - len(item)), mode=\"constant\")\n","        elif len(item) > target_length:\n","            item = item[:target_length]\n","        processed_data.append(item)\n","    return np.array(processed_data)\n","\n","# Preprocess landmarks to match the expected input size\n","fake_landmarks = preprocess_data(fake_landmarks, target_length=1280)\n","real_landmarks = preprocess_data(real_landmarks, target_length=1280)\n","\n","# Combine data and file IDs\n","fake_file_ids = [f\"fake_file{i+1}\" for i in range(len(fake_landmarks))]\n","real_file_ids = [f\"real_file{i+1}\" for i in range(len(real_landmarks))]\n","all_landmarks = np.vstack((fake_landmarks, real_landmarks))\n","all_file_ids = fake_file_ids + real_file_ids\n","\n","# Predict scores\n","print(\"Predicting scores...\")\n","scores = model.predict_proba(all_landmarks)[:, 1]  # Use the probability for \"real\" (class 1)\n","\n","# Generate the submission file\n","print(\"Writing submission file...\")\n","with open(output_file, \"w\") as f:\n","    for file_id, score in zip(all_file_ids, scores):\n","        f.write(f\"{file_id}\\t{score:.6f}\\n\")\n","\n","print(f\"Submission file '{output_file}' created successfully!\")\n"],"metadata":{"id":"c5Ep-lCPmxJS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1737291042018,"user_tz":-330,"elapsed":747,"user":{"displayName":"SP cup DFD","userId":"05376908248595937360"}},"outputId":"d09610d9-0f06-406b-88e8-9a1a791341f5"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading model...\n","Loading validation data...\n","Preparing data...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [12:50:39] WARNING: /workspace/src/gbm/gbtree.cc:363: \n","  Loading from a raw memory buffer (like pickle in Python, RDS in R) on a CPU-only\n","  machine. Consider using `save_model/load_model` instead. See:\n","\n","    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n","\n","  for more details about differences between saving model and serializing.  Changing `tree_method` to `hist`.\n","  warnings.warn(smsg, UserWarning)\n","/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [12:50:39] WARNING: /workspace/src/gbm/gbtree.cc:388: Changing updater from `grow_gpu_hist` to `grow_quantile_histmaker`.\n","  warnings.warn(smsg, UserWarning)\n","/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [12:50:39] WARNING: /workspace/src/context.cc:43: No visible GPU is found, setting device to CPU.\n","  warnings.warn(smsg, UserWarning)\n","/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [12:50:39] WARNING: /workspace/src/context.cc:196: XGBoost is not compiled with CUDA support.\n","  warnings.warn(smsg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Predicting scores...\n","Writing submission file...\n","Submission file 'submission.txt' created successfully!\n"]}]}]}