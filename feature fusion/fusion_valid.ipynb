{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2227,"status":"ok","timestamp":1736676589641,"user":{"displayName":"SP cup DFD","userId":"05376908248595937360"},"user_tz":-330},"id":"VdbpMYEKC0XA","outputId":"3fb999d5-b14a-4a86-e0e2-6d252fb66606"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.10/dist-packages (0.23.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (3.12.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (24.2)\n","Requirement already satisfied: typeguard\u003c3.0.0,\u003e=2.7 in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (2.13.3)\n","Requirement already satisfied: numpy\u003e=1.19.3 in /usr/local/lib/python3.10/dist-packages (from h5py) (1.26.4)\n"]}],"source":["pip install tensorflow-addons h5py tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"toZ5cC8tC7zu"},"outputs":[{"ename":"ValueError","evalue":"mount failed","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-3-d5df0069828e\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 2\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         )\n\u001b[0;32m--\u003e 277\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: mount failed"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","output_embedded_package_id":"1UaQI1C7jBfRpAVAlfRfBicmz2nXk3u_W"},"id":"tpYs_GV9CrUW","outputId":"cc2e1a95-4629-45be-bb00-e8c771566ffc"},"outputs":[{"data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{},"output_type":"display_data"}],"source":["import numpy as np\n","import pickle\n","from tqdm import tqdm\n","import tensorflow as tf\n","from sklearn.decomposition import PCA\n","import os\n","import h5py\n","from PIL import Image\n","\n","# GPU Configuration\n","physical_devices = tf.config.list_physical_devices('GPU')\n","if physical_devices:\n","    for device in physical_devices:\n","        try:\n","            tf.config.experimental.set_memory_growth(device, True)\n","            tf.config.set_logical_device_configuration(\n","                device, [tf.config.LogicalDeviceConfiguration(memory_limit=13000)]\n","            )\n","            print(\"Configured GPU with a memory limit of 13,000 MB.\")\n","        except Exception as e:\n","            print(f\"Error configuring GPU: {e}\")\n","else:\n","    print(\"No GPU detected, running on CPU.\")\n","\n","try:\n","    tf.keras.mixed_precision.set_global_policy('mixed_float16')\n","    print(\"Mixed precision enabled for speedup.\")\n","except ValueError:\n","    print(\"Mixed precision not supported, running with default precision.\")\n","\n","# File paths\n","spatial_fake_path = 'drive/MyDrive/features/spatial_valid_fake.pkl'\n","spatial_real_path = 'drive/MyDrive/features/spatial_valid_real.pkl'\n","landmark_fake_path = 'drive/MyDrive/features/landmarks_fake_valid.pkl'\n","landmark_real_path = 'drive/MyDrive/features/landmarks_real_valid.pkl'\n","fused_output_path = 'drive/MyDrive/features/fused_features.h5'\n","os.makedirs(os.path.dirname(fused_output_path), exist_ok=True)\n","\n","# Function to load and preprocess images from file paths inside dictionaries\n","def load_and_preprocess_images(file_data, process_images=True):\n","    processed_images = []\n","    for data in tqdm(file_data, desc=\"Loading images\"):\n","        try:\n","            image_path = data.get('image_name')  # Updated key for image path\n","            if process_images and image_path:\n","                image = Image.open(image_path).convert(\"RGB\")  # Open and convert to RGB\n","                image = image.resize((224, 224))  # Resize to a fixed size\n","                image_array = np.array(image, dtype=np.float32) / 255.0  # Normalize\n","                processed_images.append(image_array)\n","            elif not process_images:\n","                features = data.get('features')  # Use features directly if no image loading\n","                if features is not None:\n","                    processed_images.append(features)\n","                else:\n","                    print(f\"Warning: No features found in data: {data}\")\n","            else:\n","                print(f\"Warning: No image path found in data: {data}\")\n","        except Exception as e:\n","            print(f\"Error loading image {data.get('image_name', 'Unknown')}: {e}\")\n","    return np.array(processed_images)\n","\n","# Adjusted data loading with feature-only handling\n","print(\"Converting file paths to image arrays...\")\n","spatial_fake = load_and_preprocess_images(spatial_fake_data, process_images=True)\n","spatial_real = load_and_preprocess_images(spatial_real_data, process_images=True)\n","landmark_fake = load_and_preprocess_images(landmark_fake_data, process_images=True)\n","landmark_real = load_and_preprocess_images(landmark_real_data, process_images=True)\n","\n","# Function to load features\n","def load_features(file_path):\n","    with open(file_path, 'rb') as f:\n","        data = pickle.load(f)\n","        return data\n","\n","# Data augmentation function\n","def augment_data(features, target_size):\n","    current_size = len(features)\n","    augmented_samples = []\n","    while len(augmented_samples) + current_size \u003c target_size:\n","        sample = features[np.random.randint(current_size)]\n","        noise = np.random.normal(0, 0.01, sample.shape)\n","        augmented_samples.append(sample + noise)\n","    return np.concatenate([features, np.stack(augmented_samples)], axis=0)\n","\n","# Align features by padding\n","def align_features(features):\n","    max_shape = tuple(np.max([np.array(f).shape for f in features], axis=0))\n","    aligned_features = []\n","    for feature in features:\n","        feature = np.array(feature)\n","        pad_width = [(0, max_dim - cur_dim) for cur_dim, max_dim in zip(feature.shape, max_shape)]\n","        aligned_features.append(np.pad(feature, pad_width, mode='constant'))\n","    return np.stack(aligned_features, axis=0)\n","\n","# PCA for dimensionality reduction\n","def apply_pca(features, variance_threshold=0.95):\n","    reshaped_features = features.reshape(features.shape[0], -1)\n","    pca = PCA(n_components=variance_threshold)\n","    reduced_features = pca.fit_transform(reshaped_features)\n","    print(f\"PCA reduced dimensions from {reshaped_features.shape[1]} to {reduced_features.shape[1]} \"\n","          f\"(explained variance: {pca.explained_variance_ratio_.sum():.2f})\")\n","    return reduced_features\n","\n","# Load features\n","print(\"Loading features...\")\n","spatial_fake_data = load_features(spatial_fake_path)\n","spatial_real_data = load_features(spatial_real_path)\n","landmark_fake_data = load_features(landmark_fake_path)\n","landmark_real_data = load_features(landmark_real_path)\n","\n","# Convert dictionaries with file paths to image arrays\n","print(\"Converting file paths to image arrays...\")\n","spatial_fake = load_and_preprocess_images(spatial_fake_data)\n","spatial_real = load_and_preprocess_images(spatial_real_data)\n","landmark_fake = load_and_preprocess_images(landmark_fake_data)\n","landmark_real = load_and_preprocess_images(landmark_real_data)\n","\n","# Balance the dataset\n","print(\"Balancing the dataset...\")\n","if len(spatial_fake) \u003c len(spatial_real):\n","    spatial_fake = augment_data(spatial_fake, len(spatial_real))\n","if len(landmark_fake) \u003c len(landmark_real):\n","    landmark_fake = augment_data(landmark_fake, len(landmark_real))\n","\n","# Align features\n","print(\"Aligning features...\")\n","aligned_spatial_fake = align_features(spatial_fake)\n","aligned_spatial_real = align_features(spatial_real)\n","aligned_landmark_fake = align_features(landmark_fake)\n","aligned_landmark_real = align_features(landmark_real)\n","\n","# Fuse features\n","print(\"Fusing features...\")\n","fused_fake = np.concatenate([aligned_spatial_fake, aligned_landmark_fake], axis=-1)\n","fused_real = np.concatenate([aligned_spatial_real, aligned_landmark_real], axis=-1)\n","\n","# Apply PCA\n","print(\"Applying PCA for dimensionality reduction...\")\n","pca_fake = apply_pca(fused_fake)\n","pca_real = apply_pca(fused_real)\n","\n","# Save fused features\n","print(\"Saving fused features...\")\n","with h5py.File(fused_output_path, 'w') as h5f:\n","    h5f.create_dataset('pca_fake_features', data=pca_fake)\n","    h5f.create_dataset('pca_real_features', data=pca_real)\n","\n","print(f\"PCA-reduced features successfully saved to {fused_output_path}.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":391},"executionInfo":{"elapsed":2401,"status":"error","timestamp":1736616993931,"user":{"displayName":"SP cup DFD","userId":"05376908248595937360"},"user_tz":-330},"id":"SsnT31MLDvvj","outputId":"bc65470b-f71e-4ed8-8532-18454119b0d7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Configured 1 GPU(s) for memory growth.\n"]},{"ename":"TypeError","evalue":"float() argument must be a string or a real number, not 'dict'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-17-79152d25db81\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 102\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0mconfigure_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 104\u001b[0;31m     \u001b[0mprocess_and_fuse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspatial_fake_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspatial_real_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlandmark_fake_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlandmark_real_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfused_output_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m\u003cipython-input-17-79152d25db81\u003e\u001b[0m in \u001b[0;36mprocess_and_fuse\u001b[0;34m(spatial_fake_path, spatial_real_path, landmark_fake_path, landmark_real_path, fused_output_path)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mlandmark_real_future\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlandmark_real_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 66\u001b[0;31m         \u001b[0mspatial_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspatial_fake_future\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0mspatial_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspatial_real_future\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mlandmark_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlandmark_fake_future\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    456\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 458\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 403\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/concurrent/futures/thread.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 58\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m\u003cipython-input-17-79152d25db81\u003e\u001b[0m in \u001b[0;36mload_features\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Ensure consistent dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 27\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Handle list of arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Convert to NumPy array with float32 dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m\u003cipython-input-17-79152d25db81\u003e\u001b[0m in \u001b[0;36m\u003clistcomp\u003e\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Ensure consistent dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 27\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Handle list of arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Convert to NumPy array with float32 dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a real number, not 'dict'"]}],"source":["import os\n","import pickle\n","import h5py\n","import numpy as np\n","from concurrent.futures import ThreadPoolExecutor\n","from tqdm import tqdm\n","import tensorflow as tf\n","from tensorflow.keras.mixed_precision import set_global_policy\n","\n","# Set mixed precision policy\n","set_global_policy('mixed_float16')\n","\n","# File paths\n","spatial_fake_path = 'drive/MyDrive/features/spatial_valid_fake.pkl'\n","spatial_real_path = 'drive/MyDrive/features/spatial_valid_real.pkl'\n","landmark_fake_path = 'drive/MyDrive/features/landmarks_fake_valid.pkl'\n","landmark_real_path = 'drive/MyDrive/features/landmarks_real_valid.pkl'\n","fused_output_path = 'drive/MyDrive/features/fused_features.h5'\n","\n","# Load features from pickle files and convert to NumPy array\n","def load_features(file_path):\n","    with open(file_path, 'rb') as f:\n","        data = pickle.load(f)\n","    if isinstance(data, dict):\n","        data = np.array([np.array(v, dtype=np.float32) for v in data.values()], dtype=np.float32)  # Ensure consistent dtype\n","    elif isinstance(data, list):\n","        data = np.array([np.array(item, dtype=np.float32) for item in data], dtype=np.float32)  # Handle list of arrays\n","    else:\n","        data = np.array(data, dtype=np.float32)  # Convert to NumPy array with float32 dtype\n","    return data\n","\n","# Ensure shape compatibility by padding or truncating features\n","def align_shapes(features, target_shape):\n","    features = np.atleast_2d(features)  # Ensure at least 2D\n","    current_shape = features.shape\n","    if current_shape[1] \u003e target_shape[1]:\n","        features = features[:, :target_shape[1]]  # Truncate\n","    elif current_shape[1] \u003c target_shape[1]:\n","        padding = target_shape[1] - current_shape[1]\n","        features = np.pad(features, ((0, 0), (0, padding)), mode='constant', constant_values=0)  # Pad with zeros\n","    return features\n","\n","# Determine the target shape dynamically\n","def get_target_shape(*feature_arrays):\n","    max_width = 0\n","    for array in feature_arrays:\n","        if array.size == 0:  # Check if array is empty\n","            raise ValueError(\"One of the feature arrays is empty.\")\n","        array = np.atleast_2d(array)  # Ensure at least 2D\n","        max_width = max(max_width, array.shape[1])\n","    return (None, max_width)  # None for the first dimension\n","\n","# Fuse features by concatenation\n","def fuse_features(spatial_features, landmark_features):\n","    return np.concatenate([spatial_features, landmark_features], axis=1)\n","\n","# Main fusion process\n","def process_and_fuse(spatial_fake_path, spatial_real_path, landmark_fake_path, landmark_real_path, fused_output_path):\n","    # Load features\n","    with ThreadPoolExecutor(max_workers=4) as executor:\n","        spatial_fake_future = executor.submit(load_features, spatial_fake_path)\n","        spatial_real_future = executor.submit(load_features, spatial_real_path)\n","        landmark_fake_future = executor.submit(load_features, landmark_fake_path)\n","        landmark_real_future = executor.submit(load_features, landmark_real_path)\n","\n","        spatial_fake = spatial_fake_future.result()\n","        spatial_real = spatial_real_future.result()\n","        landmark_fake = landmark_fake_future.result()\n","        landmark_real = landmark_real_future.result()\n","\n","    # Determine target shape\n","    target_shape = get_target_shape(spatial_fake, spatial_real, landmark_fake, landmark_real)\n","\n","    # Align shapes\n","    spatial_fake = align_shapes(spatial_fake, target_shape)\n","    spatial_real = align_shapes(spatial_real, target_shape)\n","    landmark_fake = align_shapes(landmark_fake, target_shape)\n","    landmark_real = align_shapes(landmark_real, target_shape)\n","\n","    # Fuse features\n","    fused_fake = fuse_features(spatial_fake, landmark_fake)\n","    fused_real = fuse_features(spatial_real, landmark_real)\n","\n","    # Save fused features to an H5 file\n","    with h5py.File(fused_output_path, 'w') as h5f:\n","        h5f.create_dataset('fused_fake', data=fused_fake, compression='gzip', dtype='float32')\n","        h5f.create_dataset('fused_real', data=fused_real, compression='gzip', dtype='float32')\n","\n","    print(f\"Fused features saved to {fused_output_path}\")\n","\n","# GPU configuration\n","def configure_gpu():\n","    gpus = tf.config.experimental.list_physical_devices('GPU')\n","    if gpus:\n","        try:\n","            for gpu in gpus:\n","                tf.config.experimental.set_memory_growth(gpu, True)\n","            print(f\"Configured {len(gpus)} GPU(s) for memory growth.\")\n","        except RuntimeError as e:\n","            print(e)\n","\n","if __name__ == \"__main__\":\n","    configure_gpu()\n","    process_and_fuse(spatial_fake_path, spatial_real_path, landmark_fake_path, landmark_real_path, fused_output_path)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BajVE0jNXvxB"},"outputs":[],"source":[]}],"metadata":{"accelerator":"TPU","colab":{"authorship_tag":"ABX9TyPaWd+6xaAB3OM+2aIprfbG","gpuType":"V28","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}