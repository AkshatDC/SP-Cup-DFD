{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1lm51AbVw26XEKp3Io41e1W0kNM_1pzEN","authorship_tag":"ABX9TyPQSmerLL7ApS5X/gW3Gylt"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["pip install tensorflow keras mediapipe"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OV7ggiiXxGVs","executionInfo":{"status":"ok","timestamp":1736589113349,"user_tz":-330,"elapsed":5215,"user":{"displayName":"Deepfake Detection","userId":"16853363008574283880"}},"outputId":"5676c199-1b69-423e-cd52-2a1042e2be9f"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n","Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.5.0)\n","Collecting mediapipe\n","  Downloading mediapipe-0.10.20-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.12.23)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.69.0)\n","Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n","Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.13.1)\n","Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.3.0)\n","Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\n","Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.10.0)\n","Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.10.0.84)\n","Collecting sounddevice>=0.4.4 (from mediapipe)\n","  Downloading sounddevice-0.5.1-py3-none-any.whl.metadata (1.4 kB)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.2.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n","Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n","Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (1.13.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.55.3)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.8)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (11.1.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.2.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.18.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n","Downloading mediapipe-0.10.20-cp310-cp310-manylinux_2_28_x86_64.whl (35.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sounddevice-0.5.1-py3-none-any.whl (32 kB)\n","Installing collected packages: sounddevice, mediapipe\n","Successfully installed mediapipe-0.10.20 sounddevice-0.5.1\n"]}]},{"cell_type":"code","source":["pip install tensorflow-addons"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OkkqUAnqyCDy","executionInfo":{"status":"ok","timestamp":1736589200530,"user_tz":-330,"elapsed":3201,"user":{"displayName":"Deepfake Detection","userId":"16853363008574283880"}},"outputId":"6415cf31-4a06-4b55-abbf-0b1f1e045ba4"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow-addons\n","  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (24.2)\n","Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n","  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n","Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/611.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m471.0/611.8 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n","Installing collected packages: typeguard, tensorflow-addons\n","  Attempting uninstall: typeguard\n","    Found existing installation: typeguard 4.4.1\n","    Uninstalling typeguard-4.4.1:\n","      Successfully uninstalled typeguard-4.4.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","inflect 7.5.0 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed tensorflow-addons-0.23.0 typeguard-2.13.3\n"]}]},{"cell_type":"code","source":["import os\n","import pickle\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.applications import ResNet50\n","from tensorflow.keras.layers import Input, Dense, Flatten, Concatenate, LayerNormalization, MultiHeadAttention, Dropout\n","from tensorflow.keras.models import Model\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n","from concurrent.futures import ProcessPoolExecutor\n","from tqdm import tqdm\n","from tensorflow.keras import mixed_precision\n","\n","\n","# Step 1: GPU Utilization and Mixed Precision\n","physical_devices = tf.config.list_physical_devices('GPU')\n","if physical_devices:\n","    for device in physical_devices:\n","        try:\n","            tf.config.experimental.set_memory_growth(device, True)\n","            tf.config.set_logical_device_configuration(\n","                device, [tf.config.LogicalDeviceConfiguration(memory_limit=10000)]\n","            )\n","            print(\"Configured GPU with a memory limit of 10,000 MB.\")\n","        except Exception as e:\n","            print(f\"Error configuring GPU: {e}\")\n","else:\n","    print(\"No GPU detected, running on CPU.\")\n","\n","try:\n","    # Enable mixed precision globally\n","    policy = mixed_precision.Policy('mixed_float16')\n","    mixed_precision.set_global_policy(policy)\n","    print(f\"Mixed precision policy set to: {policy}\")\n","\n","except ValueError:\n","    print(\"Mixed precision not supported, running with default precision.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h_dR3-ynvpA0","executionInfo":{"status":"ok","timestamp":1736589438787,"user_tz":-330,"elapsed":506,"user":{"displayName":"Deepfake Detection","userId":"16853363008574283880"}},"outputId":"f79cbb07-eeae-4102-dd40-0cbdb4673eb9"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Error configuring GPU: Cannot set memory growth on device when virtual devices configured\n","Mixed precision policy set to: <DTypePolicy \"mixed_float16\">\n"]}]},{"cell_type":"code","source":["# Step 2: Load and Prepare Features with Parallel Processing\n","features_folder = 'drive/MyDrive/SP_cup/features/'\n","feature_files = {\n","    'spatial': ['merged_spatial_fake.pkl', 'spatial_features_real_images.pkl'],\n","    'landmarks': ['merged_facial_fake.pkl', 'merged_landmarks_real.pkl']\n","}\n","\n","def load_features(file_list, folder):\n","    \"\"\"Load features from a list of .pkl files.\"\"\"\n","    data = []\n","    for file in file_list:\n","        with open(os.path.join(folder, file), 'rb') as f:\n","            data.append(pickle.load(f))\n","    return np.vstack(data)  # Stack features vertically\n","\n","# Parallel feature loading\n","def load_all_features():\n","    with ProcessPoolExecutor() as executor:\n","        spatial_future = executor.submit(load_features, feature_files['spatial'], features_folder)\n","        landmark_future = executor.submit(load_features, feature_files['landmarks'], features_folder)\n","        spatial = spatial_future.result()\n","        landmarks = landmark_future.result()\n","    return spatial, landmarks\n","\n","spatial_features, landmark_features = load_all_features()\n","\n","# Create labels\n","labels = np.array([1] * (len(spatial_features) // 2) + [0] * (len(spatial_features) // 2))  # Adjust for dataset sizes\n","y = to_categorical(labels, num_classes=2)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":686},"id":"IYhi5EUWzfIo","executionInfo":{"status":"error","timestamp":1736589592763,"user_tz":-330,"elapsed":15533,"user":{"displayName":"Deepfake Detection","userId":"16853363008574283880"}},"outputId":"a88edd61-07f5-4a80-e37b-c09ed279af3d"},"execution_count":17,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (16,) + inhomogeneous part.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)","\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 246, in _process_worker\n    r = call_item.fn(*call_item.args, **call_item.kwargs)\n  File \"<ipython-input-17-53b42cf363da>\", line 14, in load_features\n    return np.vstack(data)  # Stack features vertically\n  File \"/usr/local/lib/python3.10/dist-packages/numpy/core/shape_base.py\", line 286, in vstack\n    arrs = atleast_2d(*tup)\n  File \"/usr/local/lib/python3.10/dist-packages/numpy/core/shape_base.py\", line 121, in atleast_2d\n    ary = asanyarray(ary)\nValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (16,) + inhomogeneous part.\n\"\"\"","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-53b42cf363da>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mspatial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlandmarks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mspatial_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlandmark_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_all_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Create labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-17-53b42cf363da>\u001b[0m in \u001b[0;36mload_all_features\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mspatial_future\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'spatial'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mlandmark_future\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'landmarks'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mspatial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspatial_future\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mlandmarks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlandmark_future\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mspatial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlandmarks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    456\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (16,) + inhomogeneous part."]}]},{"cell_type":"code","execution_count":10,"metadata":{"id":"krGNwobMvFJw","executionInfo":{"status":"ok","timestamp":1736589289310,"user_tz":-330,"elapsed":1462,"user":{"displayName":"Deepfake Detection","userId":"16853363008574283880"}}},"outputs":[],"source":["# Step 3: Define Transformer Block\n","class TransformerBlock(tf.keras.layers.Layer):\n","    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n","        super(TransformerBlock, self).__init__()\n","        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n","        self.ffn = tf.keras.Sequential([\n","            Dense(ff_dim, activation='relu'),\n","            Dense(embed_dim),\n","        ])\n","        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n","        self.dropout1 = Dropout(rate)\n","        self.dropout2 = Dropout(rate)\n","\n","    def call(self, inputs, training):\n","        attn_output = self.att(inputs, inputs)\n","        attn_output = self.dropout1(attn_output, training=training)\n","        out1 = self.layernorm1(inputs + attn_output)\n","        ffn_output = self.ffn(out1)\n","        ffn_output = self.dropout2(ffn_output, training=training)\n","        return self.layernorm2(out1 + ffn_output)\n"]},{"cell_type":"code","source":["# Step 4: Define the Model\n","def build_model(spatial_shape, landmark_shape):\n","    spatial_input = Input(shape=(spatial_shape,))\n","    spatial_flat = Flatten()(spatial_input)\n","\n","    landmark_input = Input(shape=(landmark_shape,))\n","    landmark_embed = Dense(128, activation='relu')(landmark_input)\n","    landmark_transformer = TransformerBlock(embed_dim=128, num_heads=4, ff_dim=512)(landmark_embed)\n","\n","    combined = Concatenate()([spatial_flat, landmark_transformer])\n","    combined_dense = Dense(256, activation='relu')(combined)\n","    output = Dense(2, activation='softmax', dtype='float32')(combined_dense)  # Float32 for mixed precision compatibility\n","\n","    model = Model(inputs=[spatial_input, landmark_input], outputs=output)\n","    model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n","    return model\n"],"metadata":{"id":"rkt7HjzSv6KZ","executionInfo":{"status":"ok","timestamp":1736589297664,"user_tz":-330,"elapsed":650,"user":{"displayName":"Deepfake Detection","userId":"16853363008574283880"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import KFold\n"],"metadata":{"id":"g6STTG1BzMdF","executionInfo":{"status":"ok","timestamp":1736589497155,"user_tz":-330,"elapsed":413,"user":{"displayName":"Deepfake Detection","userId":"16853363008574283880"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# Step 5: K-Fold Cross-Validation with k=2\n","kf = KFold(n_splits=2, shuffle=True, random_state=42)\n","fold = 1\n","spatial_shape = spatial_features.shape[1]\n","landmark_shape = landmark_features.shape[1]\n","\n","# Initialize variables to store fold metrics\n","fold_accuracies = []\n","fold_losses = []\n","\n","for train_index, val_index in kf.split(spatial_features):\n","    print(f\"\\n--- Fold {fold} ---\")\n","\n","    spatial_train, spatial_val = spatial_features[train_index], spatial_features[val_index]\n","    landmark_train, landmark_val = landmark_features[train_index], landmark_features[val_index]\n","    y_train, y_val = y[train_index], y[val_index]\n","\n","    model = build_model(spatial_shape, landmark_shape)\n","\n","    # Callbacks for progress saving\n","    checkpoint_cb = ModelCheckpoint(f'model_checkpoint_fold{fold}.h5', save_best_only=True)\n","    logger_cb = CSVLogger(f'training_log_fold{fold}.csv', append=True)\n","\n","    # Train model\n","    with tqdm(total=50, desc=f\"Training Fold {fold}\") as pbar:\n","        history = model.fit(\n","            [spatial_train, landmark_train], y_train,\n","            validation_data=([spatial_val, landmark_val], y_val),\n","            batch_size=32,\n","            epochs=50,\n","            shuffle=True,\n","            callbacks=[checkpoint_cb, logger_cb],\n","            verbose=0\n","        )\n","        pbar.update(50)\n","\n","    # Evaluate model\n","    val_loss, val_acc = model.evaluate([spatial_val, landmark_val], y_val, verbose=0)\n","    print(f\"Validation Accuracy for Fold {fold}: {val_acc * 100:.2f}%\")\n","    fold_accuracies.append(val_acc * 100)\n","    fold_losses.append(val_loss)\n","\n","    fold += 1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"id":"Olq2EQR5vSin","executionInfo":{"status":"error","timestamp":1736589504028,"user_tz":-330,"elapsed":429,"user":{"displayName":"Deepfake Detection","userId":"16853363008574283880"}},"outputId":"dd6ec0eb-a2cb-457c-fc92-c4e9d9741070"},"execution_count":16,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'spatial_features' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-df91288486e8>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mkf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mspatial_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspatial_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mlandmark_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlandmark_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'spatial_features' is not defined"]}]},{"cell_type":"code","source":["# Step 6: Aggregate and Display Metrics\n","print(\"\\n--- K-Fold Cross-Validation Results ---\")\n","print(f\"Average Accuracy: {np.mean(fold_accuracies):.2f}%\")\n","print(f\"Average Loss: {np.mean(fold_losses):.4f}\")\n","print(f\"Accuracies per Fold: {fold_accuracies}\")"],"metadata":{"id":"6IyVfntYvPnl"},"execution_count":null,"outputs":[]}]}